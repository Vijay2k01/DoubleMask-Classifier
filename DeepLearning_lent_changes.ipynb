{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_lent changes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DOUBLE MASK DETECTION**"
      ],
      "metadata": {
        "id": "gpj6M2437w6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEAM MEMBERS :**\n",
        "\n",
        "1.VIJAY KUMAR.P - 19BCE7306\n",
        "\n",
        "2.GUNTUPALLI TANUSH - 19BCE7297 (A SLOT)\n",
        "\n",
        "3.NARRA NIVAS - 19BCE7635 (A SLOT)\n",
        "\n",
        "4.G.SIVA NAGA SAI BABU - 19BCE7452 \n"
      ],
      "metadata": {
        "id": "WltqFUQT73aY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GUktx-WZq-xJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout, AveragePooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import imutils\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy_7S-FHI4KW",
        "outputId": "8177b9f8-85f8-4c3b-f7a9-5d364ba6a805"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJVmttzJ2F-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc9dce9-46c4-42f3-f046-bf162ada3444"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "x_train=train_datagen.flow_from_directory(\"/content/gdrive/MyDrive/dataset (1)/Train\",target_size=(224,224),batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 382 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYYIjC1y2F-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4423ad44-ebb3-416f-80d1-ec43251cdbdf"
      },
      "source": [
        "print(x_train.class_indices)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Double mask': 0, 'Single mask': 1, 'Without mask': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8neY59282F-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1de92c8-b958-4435-f374-caf224cd3fb0"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "x_test=test_datagen.flow_from_directory(\"/content/gdrive/MyDrive/dataset (1)/Test\",target_size=(224,224),batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkM2VPZzVSBl"
      },
      "source": [
        "# Alexnet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQZQn1PQVVxE"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters = 96, input_shape = (224, 224, 3),\n",
        "\t\t\tkernel_size = (11, 11), strides = (4, 4),\n",
        "\t\t\tpadding = 'valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Max-Pooling\n",
        "model.add(MaxPooling2D(pool_size = (2, 2),\n",
        "\t\t\tstrides = (2, 2), padding = 'valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters = 256, kernel_size = (11, 11),\n",
        "\t\t\tstrides = (1, 1), padding = 'valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Max-Pooling\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),\n",
        "\t\t\tpadding = 'valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters = 384, kernel_size = (3, 3),\n",
        "\t\t\tstrides = (1, 1), padding = 'valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters = 384, kernel_size = (3, 3),\n",
        "\t\t\tstrides = (1, 1), padding = 'valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3, 3),\n",
        "\t\t\tstrides = (1, 1), padding = 'valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Max-Pooling\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),\n",
        "\t\t\tpadding = 'valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape = (224*224*3, )))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Softmax Layer\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc'])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZYIunr2VjxY",
        "outputId": "179ddc8a-6a5f-4a02-cfff-bdd6fa3d930d"
      },
      "source": [
        "#steps per epoch=279/30;validation_step=120/30\n",
        "history=model.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 0.2609 - acc: 0.9005 - val_loss: 2.3991 - val_acc: 0.6214\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 0.2785 - acc: 0.9188 - val_loss: 2.1074 - val_acc: 0.6786\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 7s 599ms/step - loss: 0.3224 - acc: 0.8927 - val_loss: 2.1487 - val_acc: 0.6429\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 586ms/step - loss: 0.2468 - acc: 0.9110 - val_loss: 1.9733 - val_acc: 0.6571\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 7s 589ms/step - loss: 0.2702 - acc: 0.9084 - val_loss: 1.8796 - val_acc: 0.6357\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.2637 - acc: 0.9084 - val_loss: 2.0739 - val_acc: 0.6143\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 0.2043 - acc: 0.9162 - val_loss: 2.2391 - val_acc: 0.6286\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 7s 606ms/step - loss: 0.2743 - acc: 0.9058 - val_loss: 2.3482 - val_acc: 0.6071\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 7s 604ms/step - loss: 0.1998 - acc: 0.9293 - val_loss: 1.8556 - val_acc: 0.6786\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 8s 688ms/step - loss: 0.1268 - acc: 0.9660 - val_loss: 1.8622 - val_acc: 0.6500\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 7s 618ms/step - loss: 0.0969 - acc: 0.9607 - val_loss: 2.0405 - val_acc: 0.6714\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 612ms/step - loss: 0.1196 - acc: 0.9529 - val_loss: 2.0819 - val_acc: 0.6357\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 0.0786 - acc: 0.9686 - val_loss: 1.9938 - val_acc: 0.6643\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 7s 624ms/step - loss: 0.1209 - acc: 0.9712 - val_loss: 2.3069 - val_acc: 0.7000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 0.2519 - acc: 0.9346 - val_loss: 1.9909 - val_acc: 0.6571\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 605ms/step - loss: 0.2050 - acc: 0.9424 - val_loss: 2.7720 - val_acc: 0.6786\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 595ms/step - loss: 0.2125 - acc: 0.9346 - val_loss: 1.8065 - val_acc: 0.6643\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 7s 592ms/step - loss: 0.2905 - acc: 0.9267 - val_loss: 2.2632 - val_acc: 0.6214\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 0.1387 - acc: 0.9555 - val_loss: 2.2845 - val_acc: 0.6929\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 0.1705 - acc: 0.9529 - val_loss: 2.9081 - val_acc: 0.6143\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.2619 - acc: 0.9162 - val_loss: 2.3880 - val_acc: 0.6143\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 8s 708ms/step - loss: 0.1830 - acc: 0.9398 - val_loss: 2.3748 - val_acc: 0.6214\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 616ms/step - loss: 0.2220 - acc: 0.9215 - val_loss: 1.9941 - val_acc: 0.6429\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 0.1936 - acc: 0.9398 - val_loss: 2.2044 - val_acc: 0.7071\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 7s 592ms/step - loss: 0.1743 - acc: 0.9476 - val_loss: 1.7559 - val_acc: 0.6500\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 0.1620 - acc: 0.9476 - val_loss: 2.1540 - val_acc: 0.6429\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 7s 604ms/step - loss: 0.1687 - acc: 0.9241 - val_loss: 2.6034 - val_acc: 0.6643\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 7s 586ms/step - loss: 0.2332 - acc: 0.9398 - val_loss: 2.3723 - val_acc: 0.6714\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 0.1678 - acc: 0.9346 - val_loss: 2.5758 - val_acc: 0.6571\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 610ms/step - loss: 0.2926 - acc: 0.9319 - val_loss: 2.3119 - val_acc: 0.6786\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 0.2855 - acc: 0.9162 - val_loss: 2.1310 - val_acc: 0.6571\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 7s 592ms/step - loss: 0.2060 - acc: 0.9346 - val_loss: 2.4982 - val_acc: 0.6429\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.1979 - acc: 0.9372 - val_loss: 1.7181 - val_acc: 0.6857\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 0.1735 - acc: 0.9372 - val_loss: 1.6136 - val_acc: 0.6857\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 599ms/step - loss: 0.0919 - acc: 0.9686 - val_loss: 1.2753 - val_acc: 0.7071\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.1272 - acc: 0.9634 - val_loss: 2.2893 - val_acc: 0.6786\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 629ms/step - loss: 0.1089 - acc: 0.9607 - val_loss: 1.9580 - val_acc: 0.6429\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 0.0869 - acc: 0.9686 - val_loss: 1.8174 - val_acc: 0.6929\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 0.0704 - acc: 0.9791 - val_loss: 2.2548 - val_acc: 0.7214\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 7s 577ms/step - loss: 0.1716 - acc: 0.9450 - val_loss: 1.9407 - val_acc: 0.6714\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 586ms/step - loss: 0.0685 - acc: 0.9764 - val_loss: 2.1404 - val_acc: 0.6643\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 0.1268 - acc: 0.9581 - val_loss: 1.8783 - val_acc: 0.6500\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 0.0795 - acc: 0.9791 - val_loss: 2.3489 - val_acc: 0.6929\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.1852 - acc: 0.9424 - val_loss: 2.4730 - val_acc: 0.6786\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 618ms/step - loss: 0.1395 - acc: 0.9476 - val_loss: 2.0891 - val_acc: 0.6857\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 0.1425 - acc: 0.9503 - val_loss: 2.2368 - val_acc: 0.6643\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 7s 627ms/step - loss: 0.1095 - acc: 0.9634 - val_loss: 1.7192 - val_acc: 0.6857\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.0693 - acc: 0.9791 - val_loss: 2.0817 - val_acc: 0.6857\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 0.0356 - acc: 0.9895 - val_loss: 2.4493 - val_acc: 0.6929\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 584ms/step - loss: 0.0583 - acc: 0.9712 - val_loss: 2.3124 - val_acc: 0.6786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss = history.history['loss']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, test_loss, 'b-')\n",
        "plt.legend(['epoch', 'Test Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "vfkckQVf0MSK",
        "outputId": "8c5ceb3d-e26f-460d-c825-a57cab2ac862"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXhU1fnHv28WQBZZAyqLQQUVkhAkgiwRkEVBBEWs9AcuBYo7UpVq1YILVmmpINpqca+iUkEFS6hFkYCELWGTRZCyBgKEQMIaIMn7++Od60wms9yZzJ31/TzPPDNz13Nn7j3f8y7nHGJmKIqiKLFLXKgLoCiKooQWFQJFUZQYR4VAURQlxlEhUBRFiXFUCBRFUWIcFQJFUZQYJ8GqAxNRLQBLAdS0nWcOM09y2qYmgH8C6ASgCMCdzLzb03GbNGnCycnJVhRZURQlasnLyzvCzEmu1lkmBADOAriBmU8SUSKAH4hoITOvdNhmNIBjzHwFEQ0HMAXAnZ4OmpycjNzcXOtKrSiKEoUQ0R536yxzDbFw0vY10fZy7r02BMCHts9zAPQhIrKqTIqiKEpVLI0REFE8Ea0HcBjAImZe5bRJcwD7AICZywCUAGhsZZkURVGUylgqBMxczszpAFoA6ExEKf4ch4jGElEuEeUWFhYGtpCKoigxjpUxgl9g5mIi+h7ATQA2OazaD6AlgHwiSgBQHxI0dt5/JoCZAJCRkaGDIylKlHP+/Hnk5+ejtLQ01EWJOGrVqoUWLVogMTHR9D5WZg0lAThvE4ELAPSDBIMdmQ/gHgArAAwDsJh1FDxFiXny8/NRr149JCcnQ8OG5mFmFBUVIT8/H61btza9n5WuoYsBfE9EGwGsgcQI/k1ELxDRYNs27wJoTEQ7ADwG4CkLy6MoSoRQWlqKxo0bqwj4CBGhcePGPltSllkEzLwRQEcXyyc6fC4FcIdVZVAUJXJREfAPf3437VmsRDRnzgDvvgtUVIS6JIoSuagQKBHNF18AY8YAy5eHuiSKYo4lS5Zg0KBBoS5GJVQIlIhm2zZ5//HH0JZDUSIZFQIlovn5Z3lXIVACzccff4zOnTsjPT0d9913H8rLy1G3bl387ne/Q/v27dGnTx8Y/ZrWr1+P6667Dmlpabjttttw7NgxAMCOHTvQt29fdOjQAddccw3+97//AQBOnjyJYcOG4aqrrsKIESMQ6mRJFQIlojGEYNMmz9spEU6vXlVff/+7rDt92vX6Dz6Q9UeOVF3nha1bt2L27NlYvnw51q9fj/j4eMyaNQunTp1CRkYGNm/ejJ49e+L5558HANx9992YMmUKNm7ciNTU1F+WjxgxAg899BA2bNiAnJwcXHzxxQCAdevWYfr06diyZQt27tyJ5SH2bQalQ5miWAFzZSFgBjTRRAkE3333HfLy8nDttdcCAM6cOYOmTZsiLi4Od94p42KOHDkSQ4cORUlJCYqLi9GzZ08AwD333IM77rgDJ06cwP79+3HbbbcBkI5eBp07d0aLFi0AAOnp6di9ezd69OgRzEushAqBErEUFgLHjwNt2wLbtwP79wO2Z0uJNpYscb+udm3P65s08bzeBcyMe+65By+//HKl5S+++GKl7/6muNasWfOXz/Hx8SgrK/PrOIFCXUNKxGJYA0OHyru6h5RA0adPH8yZMweHDx8GABw9ehR79uxBRUUF5syZAwD45JNP0KNHD9SvXx8NGzbEsmXLAAAfffQRevbsiXr16qFFixb46quvAABnz57F6dOnQ3NBXlAhUCIWQwhslrcGjJWA0a5dO0yePBn9+/dHWloa+vXrh4KCAtSpUwerV69GSkoKFi9ejIkTpX/shx9+iAkTJiAtLQ3r16//ZflHH32EGTNmIC0tDd26dcPBgwdDeVluoVBHq30lIyODdWKayOH0abHcreCZZ4ApU6RTWXIy0Lcv8OGHXndTIoCtW7fi6quvDnUxqlC3bl2cPHnS+4YhxtXvR0R5zJzhanu1CBTLyM8HGjb02T1rmp9/Blq3BhITgdRUdQ0pir+oECiWsWULcO6cdRX0zz8DbdrI55QUOV95uTXnUhQAEWEN+IMKgWIZ+/bJuxVuUSN11FEISksBW38dRVF8QIVAsYy9e+XdCiE4eBA4dcouBKmp8q4BY0XxHRUCxTKstAiMjCFDCK6+WjqTaZxAUXxHhUCxDCstAmchqF0buOIKtQgUxR+0Z7FiGVZbBImJQKtW9mUpKWoRKNWnqKgIffr0AQAcPHgQ8fHxSEpKAgCsXr0aNWrU8Lj/kiVLUKNGDXTr1q3Kug8++AC5ubl44403Al/waqBCoFgCs90iOHRIJo6JC6D9uX07cPnlQILDHZyaCsybJ0Fjh2FdFMUnGjdujPXr1wMAnnvuOdStWxdPPPGE6f2XLFmCunXruhSCcEVdQ4olHDkiFfLllwNlZcDRo4E9vmPGkEFKigjO1q2BPZei5OXloWfPnujUqRNuvPFGFBQUAABmzJiBdu3aIS0tDcOHD8fu3bvx1ltvYdq0aUhPT/9l2AlvvPrqq0hJSUFKSgqmT58OADh16hRuvvlmdOjQASkpKZg9ezYA4KmnnvrlnL4IlCfUIlAswXALde4sKZ0HD8rYX4GgogLYsQPo37/y8pQUed+0CehYZbZsJVIZPx6wNdADRno6YKtvvcLMeOSRRzBv3jwkJSVh9uzZeOaZZ/Dee+/hlVdewa5du1CzZk0UFxejQYMGuP/++32yIvLy8vD+++9j1apVYGZ06dIFPXv2xM6dO3HJJZdgwYIFAICSkhIUFRXhyy+/xE8//QQiQnFxsb8/QSXUIlAswXAL2UbxDWicYP9+sTacLYI2bYAaNTRgrASWs2fPYtOmTejXrx/S09MxefJk5OfnAwDS0tIwYsQIfPzxx0hI8K9d/cMPP+C2225DnTp1ULduXQwdOhTLli1DamoqFi1ahCeffBLLli1D/fr1Ub9+fdSqVQujR4/GF198gdoBGr9FLQLFEgyLwAohcM4YMkhIkDTScA4Y/+c/QOPG9t9F8Y7ZlrtVMDPat2+PFStWVFm3YMECLF26FF9//TVeeukl/BjAVkjbtm2xdu1aZGVl4dlnn0WfPn0wceJErF69Gt999x3mzJmDN954A4sXL672udQiUCxh716gZk17R69gCAEQ3mMOMQP33iuvCBvrMaapWbMmCgsLfxGC8+fPY/PmzaioqMC+ffvQu3dvTJkyBSUlJTh58iTq1auHEydOmD5+ZmYmvvrqK5w+fRqnTp3Cl19+iczMTBw4cAC1a9fGyJEjMWHCBKxduxYnT55ESUkJBg4ciGnTpmHDhg0BuUa1CBRL2LcPaNkSuPBC4IILAi8EtWq5noQmJQX4+GOguBho0CBw5wwE+/dLBtWhQ8DKlUDXrt732blTZlycNAmIj7e8iIoL4uLiMGfOHIwbNw4lJSUoKyvD+PHj0bZtW4wcORIlJSVgZowbNw4NGjTALbfcgmHDhmHevHl4/fXXkZmZWel4H3zwwS9zFADAypUrce+996Jz584AgDFjxqBjx4745ptvMGHCBMTFxSExMRFvvvkmTpw4gSFDhqC0tBTMjFdffTUwF8nMEfXq1KkTK+FP167MN9wgn1u3Zh4xInDHHjyYuX171+sWLGAGmH/4IXDnCxRffSVlA5hHjTK3z/Dhsv2iRdaWLdzYsmVLqIsQ0bj6/QDkspt6VV1DiiXs3SsWAQBcdJG0ggOFq9RRAyNzKBwDxnl50qr/v/8DPvtMptn0xN69wOefy2db5qCiWIJlQkBELYnoeyLaQkSbiehRF9v0IqISIlpve020qjxK8Dh/HigosPf6veiiwLmGysslHdWdEBjuqHCME+TmAu3aAePGyYQ93ip3o/Npr17A3LkypLeiWIGVFkEZgMeZuR2A6wA8RETtXGy3jJnTba8XLCyPEiQOHJBcf0eLIFBCsG+fVIjuhIBIrIJwswiYxSLIyJC+FSkpwDvvuN/+xAlg5kxg2DDg8ceBY8eAb78NXnnDAdaIul/487tZJgTMXMDMa22fTwDYCqC5VedTwgcjddTRIjhyRCyF6uIpY8jAGHMonOqR/Hzg8GGgUycRqzFjgNWrgY0bXW///vtASQnwu99Jx7kGDcSdVB0KCqQMkUCtWrVQVFSkYuAjzIyioiLU8nGMlaBkDRFRMoCOAFa5WN2ViDYAOADgCWbe7GL/sQDGAkArx1HGlLDE6EzmKASAVELNq9kUMCMEqanSmj54ELj44uqdL1Dk5cl7p07yPnIk8PvfA+++C7z2WuVty8tlWbduQJcusmzoUIkXVGccpSFDgGbNgK+/9m//YNKiRQvk5+ejsLAw1EWJOGrVqoUWrlLqPGC5EBBRXQBzAYxnZufw2FoAlzLzSSIaCOArAFUecWaeCWAmIJPXW1xkpZoYFoGjawiQijkQQlC7NnDJJe63cQwYh5MQxMcDHTrI98aNpXL/6CNgypTKlfv8+ZI2OmWKfdnw4cB77wELFwK33eb7+Y8dkxiFJwENJxITE9G6deuQnPvECeDvfwceeUTutVjA0qwhIkqEiMAsZv7CeT0zH2fmk7bPWQASiShAI9IooWLvXpm0vm5d+e4oBNVl+3aZd4DI/TaOYw6FC7m5QPv20qfCYMwYqaC//LLyttOmAcnJwK232pf17g0kJfnvHlq2zD4irHpb3MMM3Hcf8NRTwBdVaqzoxcqsIQLwLoCtzOyy1wMRXWTbDkTU2VaeIqvKpAQHx9RRILBC4Cl11KBJEzlnuASMHQPFjvTuDbRuXTlovGaNVNqPPlp5iO2EBAkc//vfMkWnr2Rny3tpqcRrFNf885/Ap5/K5+XLg3/+Q4fEtWn8X8HCSougO4C7ANzgkB46kIjuJ6L7bdsMA7DJFiOYAWA4a3Qo4tm3r/KEMc2ayXt1haCsDNi1y5x7I5wmqdm3DygstMcHDOLigNGjgcWLJSUWEGugXj1g1Kiqxxk+XNJO/fHxZ2fbeyYbrjulMtu3Aw89JOm6/foBP/wQ/DL85z9y3957L3DyZPDOa2XW0A/MTMyc5pAemsXMbzHzW7Zt3mDm9szcgZmvY+Ycq8qjBA9ni6BmTcl6qa4Q7N4tYmBGCFJTgc2bJY011BiBYmeLAJAHPi5O/P/79klA+Le/lb4QzvToIbERXzuXlZQA69YBN90k341gvmLn7FkR2po1ZYiSnj2lQj52LLjlyM4W9+GePcAf/hC888ZMz+Jt2+SH1U451nLypDw8zsldgehLYCZjyCAlBThzRoKuoSY3V1w7aWlV1zVvDgwYIOmi06eLcD3yiOvjxMUBv/oVkJUllbtZli+X444cKd/VIqjKH/4gYvn++/Kf9Oghy3OC3DTNzpZ04XHjpEPh0qXBOW/MCMH27cArrwBLloS6JNGNcx8Cg2ALgTHq6RNPAFOnSibO1q3S8gs2eXkSKHaX9jlmjOT4T58O3H67BIrdceed0phxGLPMK9nZMr/zLbdIi1ctgspkZYlL7uGHgcGDZdm118pvZnKCsYCQny8Nl549gZdeAi67TFyEp09bf+6YEYK+fSUVbN68UJckunFOHTUIlBDUq2ePOXgiLU1cIT/8AEyYIDn07drJPXDZZcCsWdUri1ncBYoduflmuaaKCuCxxzwfr0sX4NJLfXMPZWdLxVanjgi0CoGdggJxz6WmAn/5i3157doS0wlmnMAIEPfsKf/Vu+9K7OiPf7T+3DEjBBdcANx4owiBhqOtw7kzmUGghKBNG8+powY1a0rO/ZEjMl/yqlWSs//ssxJneOut6pXFLHv3ShmcA8WOJCYCzz0nFdJ113k+HpH4shctAopM5NedPClC1LOnfG/ZUl1DBhUVwN13y2/02WdVLbbMTMniKi0NTnmWLgXq17f3NenVC3jgAbFWXMyJE1BiRggAaRXu328P3oUrp07Jg/vii6Euie/s3SuVlXOHr4sukgfOn9RHAzOpo65o2FDG9xk5Enj+efGzr14dnAfcU6DYkfvvF/+0Ge68U8TMTJ77ihWyrSEEahHY+fhjGb/ptdfEWnSmRw9xw+XmBqc82dlyTsd5J6ZMkf9s1Chr79eYEoKbb5aAWzi7hyoqgHvukdbB/PmhLo3v7NsnIpCYWHm50ZfA3+Goz52TrKFA9IzNzAzeA24Eio2YRSBITwfatjXXucxIG+3WTb63bCmDAgZi3KdIJztb+pyMGeN6vfGbBcM9dPCgJLQYgm1Qrx7w9tvATz+J1WgVMSUETZqI4oazEDz/vAw5nJws6WtlZaEukZ3ycsnE8YRz6qhBdTuV7dolIhkIIejeXd6DEQjMyxMR8Hd8IFcQiVWwZIn33zM7W9xS9erJ91atxDV64EDgyhOprFsHdOzo3tXYpInMgR2M+8TIDnIWAkD6NIwZIzGMNWusOX9MCQEg3fZ//DE80gqd+de/gBdeEDPwuefEFDQyZcKBp5+WSs1Tbr5zZzKD6gqBLxlD3gjWA84sFoGn+IC//N//yf/gKdZx5oy4wBwrF+O/iXX30Llz0tDq2NHzdj162NNvrSQ7WwLE11zjev3UqWJpWzXsRcwJwZAh8h5uVkFengQLu3eXAa+MgFGA5qauNswiVP/7n7Sk3G0TaCE4f14qM6Pbf6AGTcvMlBzx8vLAHM8Ve/ZIoNoKIbjqKhl8bvp0mZ/ZFStXSoXnKASGtWZVwPiOO8zHOkLJli1yb3kTgsxM6bOxucqYyIElO1ue/QQ3w4DWry91xMsvW3P+mBOCyy6TzkbhJAQFBSJQSUmi+DVrSos1ISF8hOCnn8RHD0g2jiuOHBErxpVrqEkTic94E4LSUsmImTQJ6NNHeiR36QJ88om0zho3rtZl/EKPHvKAWzkMhdlAsb9MnCjXMH266/XZ2fKbG52jAPt/Y4VFUF4u9+/MmYE/dqAxGjNmLALA2jjBkSMiNK7cQo40bWpdGWJOCACpdJctM5d+ZzWlpeKuKi6W4LDxZxtiEC5CkJUl761a2T874y51FJCAZdOm3oVg+HDpWTl5svRQHj1aLJH9++U/M5M6aobMTHm30j2UmytB80AGih1JT/dsFWRnyzb169uX1a0LNGpkjRAUFYkLZfXq6g/NcPq0XJdVQe1168QV483CTE4Wl4yVQuApPhAsYlYIKiqABQtCWw5mGVdm9WrJcTfcQQYdOoSPECxcKL1j77lHcvKPHq26jVG5uLIIAO99CZjloRg2TCqStWuBGTPE3eBp/gF/uPRSoEULa4XACBTXrGndOdxZBWfPimvIVeViVV8CY/azigoZSK86fP65zM5m1SQ6a9eKSMZ5qQGJxCrwdp/s2eN/RpwxvtC11/q3fyCISSHo1EnGEwm1e2jhQsllfu4515ONdOgg2R2hHjb4xAmpoAcOlHFxKiqA//636nbuhpcw8CYEe/aIAPTp43rQtUBCJFbBDz9Y08HQykCxI+6sAqOfhCshsKovgWNFuGhR9Y5lZMe4c0NWh4oKaWB5cwsZZGbKve3uNzt6VCrx++7zrzxLlwJduwI1avi3fyCISSGIi5MxRf7zH+/pkFZRXi5TFV5+uftRBg0Lwd28tsHiu+/ERB84UDpmNWrk+gHdu1fSJJu4mVrImxAYPnV3mROBpkcPEdpdu7xv62tQefduETWr4gOOGFaB45SXxnAFjvEBg5YtrRWCK68EvvmmegJrCEFWVuCFescO6dxoVgi8xQmeflqGGV+71veyHDsmohRKtxAQo0IAiHvo9Gmp5ELBhx9KgOjll923BMIlcygrS/LQu3cXX3///iKizil1+/ZJJePOj9+smQiBuwd77Vr3o3Ragdk4wd/+Jq4pXxoNRmc1qy0CQKyCW2+VoQgMqyA7W9xSroLrrVrJdidOBLYchhDcdZcIoTHHgq+cOwesXy+/+YEDgW8ImQ0UG6Smyv3vSghWrZLgeFKS3P++jAoL2C1SFYIQ0auX/LmhcA+dPi2tuM6dxR/ujqZNpRUdSiFgFiHo18/eW3jAAPEHO6eR7t3r3i0EyLWcP+8+kOhtlM5A0769ZCV5CgSWlQF//rNcry8VUl6e/F7GtJlW42gVnD8vqbHuKhfjPwp0nODwYbnmO+6Q767ch2b48UcRg9//Xr4H2j20bp2Us317c9sbPbOd75OyMhkL6OKL7daYr1lo2dkSQ+rSxbf9Ak3MCkHNmuLq+Prr4E9e8tprkgXzl794z4JJSwutEGzaJGUdONC+7MYb5d35ATUsAnd46ktgjNIZLLcQIC7C7t09WwTz59vdKL4MSZGXJ/+dlYFiRzp2FKtg+nQJ1J4+7V4IrEohPXRIGi9t2ki2jb9CYLiFBg+W63KXpeYv69aJCPjik+/Ro+pENW++KceaNs0+HIWv06NmZ4sIBKvx446YFQJA3EOHDol554pdu6o3SJorCgvFHTR4MHD99d6379DB3vklFBgP4YAB9mXNmonv21EIzp8XM96bRQC4FoL8fO+jdFpBZqaM8WJkvDgzY4ZkGDVpYn6wQkPUgn0tEyeKy8cYO8fd/WWVRXDokNwbROI+/P57/+7bNWvEpZWcLPddTo77TnO+wmwfWsIXMjNlX2OimoICGcm2f3+xgFq1Eg+DLxbB8ePiDjVTD1hNTAvBgAHik3ac5INZbuABA6Tz2d13B/ackyeLuLzyirntO3QQM/mnnwJbDrNkZYkP2jl9c8AASU800kj375ffzl+LINiBYgMjTuBqovING6TF9vDDInxmLYIdO6TlGOx0QMMqyM+XPijuOiBdcolYQ1ZYBMZcEf37S0W3erXvx8nNld+OSCzR8nJzWUivvSZBak8cOCCNMV+FwJioxnAPPf64pOi+8YaUk0jcgL5YBMbQFaGODwAxLgQNGkisYN488ffNni1/+A03iFL37Ss9JQM1bPWOHTJ8xJgx8qCaIZQB4+JiuVkd3UIGRhqp8YB6Sx0FPAvB2rVSOTn3pbCaTp3EfePKPfT665LfPWqUCMGWLeZmizJajYa7IJhMnCjvniqXhAQRA6ssAkCeobg4391Dp09LEoUhol26yHPqLU6wfbv0OzDiCu4wMnt8FQLHiWq+/VaGPHnqqcod0lJTRQjMZjllZ8t/0bWrb2WxgpgWAkBaUNu2Set/+HDJpPjHPyTrYe5cSZUM1AxBzzwjfklfhpO98krZJxRCsGiRtMYc3UIGRhqp4Try1KvYoH59qXRddbzJy7PPIBZMjECdsxAUFcksZnfdJdfZqZP8Fmb+h+XLpfK66ipryuyJjh0lrvHss563C3RfAmZxrxlC0LChVOa+CsG6dfI7G0KQkCAxqYULPcfypk2TMmzcKILt6fhE/jU4evQQC+fBByXt+6mnKq9PTRVLsKDA3PEcZ44LNSoEt8of0bIl8OWXMq/t2LHSErzwQuDJJ+UmrO4k1qtXy1AJTzwhWQZmMbIbQiEECxdKheZq1iznNFJ3U1Q6QuS6L0EoAsWOZGZKBXHypH3ZO+9IhyxjInmjP4AZ6zAnR1p53nqtWsUtt0iHSU8Eui9BSYm4MB3dUf37+z7chBEodnSrDRgg98z69a73KSwEPvhArjsuzvM0nuvWSSveGJbbF4yJan7+WVKKnQO8RoaYGffQqVPiAgsHtxCgQoDmzeVGXb5cRMH54X3oIWnlVMcqYBaTtWlTEQJfsWKoiS1bZH5cd6mTFRUiBDfe6H5ERMc00r17peXsrXXjSggKCsRKCHZw1aBHD2mFrlwp38vK5EG/4Qb7w928ufx/3uIExcXi2giFW8gXWrWSWEKgMuYMK89xPun+/eX4339v/jhr1sjQH4YbEZC5pwH37qE33xTRnjJFXL2ffebePeNPoNjA6EczbJg9c84RY0wpM0LgPHNcqIl5IQCqzqblSJ060vN38WL/x0/55hsxAydN8q8l0qGDVLjVnfOXWVwgt9wiVsa0afKwfvtt1W3Xr5fzuYoPGDimkXpLHTVwJQShChQbdOsmDQDDPTRvnlzPuHH2bYjEKvBmERhiEglCcPastKYDgSsh6NJF7ndf3ENr1lTtjW1kqblKIz1zRgK2N98scbfhwyVe4Mp6OHpUhjHxVwiaNJGGk7thths3FmvfTOaQMXOcMUlSqFEhMMF990mL8I9/9K+7+yuvSCvH3ZR43qjuUBPG8MBdu0qq2sqVEqfYskXM5EGDqra2jIfOaI25olkzacUvXOi9M5mBKyFYu1Yq2vR0ny4rYFx4ofzGhhDMmCGpi4MGVd6uUyf5zTylFOfkiKh07mxZcQNCoPsSuBKCxESgd2/zw00UF4vbxVW2lXOWmsFHH4mYGZb27beLBetqGk9DHPwVAkDcpHXrul9vNnNoyZLKM8eFGsuEgIhaEtH3RLSFiDYT0aMutiEimkFEO4hoIxGFqE3omVq1RARycrynpzmzapWo/+9+5/+gUtXJHDpwQG7O22+XB+Zvf5NW0aRJ0oJavFisg1tvrTxHclaWPJDexkA3HtAdO8xbBIWFlafgzMuToLinB8xqMjPlOtaskUHAHn648iTigLRKjQHL3JGTI/9XKK/FDIHuS2D0w3C+X/r3Nz/chGFtuRKCgQOrDnZYUQH89a9SoRoulkaNxFL97LOqbi9fh5bwh9RUaSx4Gpvq9GmpF3r1sq4cvmKlRVAG4HFmbgfgOgAPEVE7p20GAGhje40F8KaF5akWv/mNtBKffdY3q+DPf5aA629/6/+5GzUSi8IfIXjxRXkIP/tMTOYHH6ycmdO4sYy3lJ4uYjF3rmTMrFrlOlvIGeMBPX3avEXAXNklEYrOV8706CFuhrFj5fcZNarqNkYZ3cUJysrkdwt3txAQ+CkrDx0SS8h5wMH+/eXdTD8AI1DsaqC+a6+Ve9XRcl2wQO7pJ56o3EN/+HC5LsNNZ7BunVj2SUney+IvqakSr/AkfCtWSEe7mBACZi5g5rW2zycAbAXgnMswBMA/WVgJoAER+ZBTEzxq1JBWdF6e+fGJtm2TTKSHHqq+CejPUBN79gDvviuTu9x5Z9UWrkGDBvKgdu4s2z38sFTunuIDBkYaKWBeCAC7e+jgQbFaQi0ERsey9eulE2HDhlW3ueQSKb+7OA58jm4AACAASURBVMGmTZJ5FAlC0KiRZMYFyiI4dEhEwPkeu+IK88NNrFkj27v67ePjq6aRTp0q95zzeF2DB4sV7+weqk6g2CxmMoeMmePCJT4ABClGQETJADoCcB7MoTkAx1sxH1XFImwYORJo21bcRGayLaZOlTx1x6Cjv3ToIL2Lz541v89LL0lL6emnvW974YXi9ureXR6gJk3MDaFspJEC5lxDhg/ZEAKjg0+oAsUGF10klRAgQugKIhEsdxaBkWIcTg+4O4gC25fAsTOZ83n69RMXpLfhJtas8dwbe8AAsSTz8iQtdelSYPz4qlltF14oweN//cvuojl9Wp4fq4WgXTu5Zk8BYyM+YPWcG75guRAQUV0AcwGMZ+bjfh5jLBHlElFuYaDSHPwgIQF4/nn5kz//3PO2BQXAP/8pLqVAzDXaoYO4Hjx1lnFk1y7Jbvjtb81V0ID4tbOyxLQeP969BeHM8OHSurzySu/bOlsE/vb0tIL77pOXp1EpMzKkQnHsc2CQkyNWgxnLKBwIZF8Cd0IAmBtu4tAhsU48CcGNN0olu3ChxAbq13efgDF8uBzTmJdh40ZpvFl9n9WuLQ0KdxZBOMYHAIuFgIgSISIwi5m/cLHJfgCO1VQL27JKMPNMZs5g5owkKx18JvjVr8QP+NhjwM6d7rebPl0qbn/6DbjC14Dx5MlSkbub9MYddepI9/lnnjG/z5Ah0hfDzF/jbBHk5UnmUji0jp54AnjrLc/bdOokFYqr9MScHHELBWpeZatp1SqwwWJ3DR4zw00YVpYnKzQpSVyRH34IzJkjou3O5TpwoDRsPv1UvhuB4mBYnp4yh1aulE5pMSMEREQA3gWwlZlfdbPZfAB327KHrgNQwswmO2iHhrg4GXqgtFSmVHT1IJWUSIVyxx0ydEUgaNNGWt1mhGDHDnlYjLTXYGB2uOXataXSdxSCUMcHfMEoq3OcoKBArLBIiA8YtGol5fbF3egOTxZBo0bS0p89WypBV6xZI8+Wt4p6wABpgMXF2Xt9u6J2bWmgzJ0r51y3TmIPwbDWUlPlGXQ1kZERH3A1c1wosdIi6A7gLgA3ENF622sgEd1PRPfbtskCsBPADgBvA3jQwvIEjNRUad0cPSqtHeexRd56S0zhJ58M3Dnj46WlYUYIJk+WHG7nsVDCBaMvQWGhCGkkCcEll0inIec4wYoV8h5JQmC4DPdXscF949QpebkTAkCy7bZtkyw6V6xZI/51bz3TjQSGX/9aMuk88etfi6W6aJE9UBwMay01VazGrVurrluyRMQuHCxgR6zMGvqBmYmZ05g53fbKYua3mPkt2zbMzA8x8+XMnMrMPkz9EVqMjlQFBTJKqRG6KC0Vt1C/foH3RxpDTXhKX92+XTrZPPigb2MaBRNDCMIlUOwrrnoY5+SIVRQOsQ6zBKovgavOZM4MGiQZaS++WLWCZPYeKDbIyJDn6+WXvW/br59YAR99JK6aYP037jKHzpwR11C4uYUA7VlcLbp1A/79bzFV+/eX1sdHH0kl5204XH/o0EGskAMH3G/zwgtSIVlx/kAR6ULQqZMEjB3n/M3JkYrM306DoSBQfQnMCAEg8wXUqSMJDI5Zd3v3SkPKjBAQAY8+as7lWaOG9I35/HNxfwVLCK64Qp5B58yhcI0PACoE1aZXL5nYZssWyWr4y1+kYuvTJ/Dn8hYw3rpVgmMPP+z9oQwlF10klUdensRQGjQIdYl8IyNDWrFGwLi0VK4lktxCgN21Ul0hcNer2JlmzWR8q+XLZah3A1cjjgaK4cPtohMsIUhIEDeXs0UQrvEBQIUgINx4o+Qsr1snY6U8+aQ1vsi0NHl3JwQvvCAB5QkTAn/uQHLRRRJQz8mJrPiAgXMP47VrpaUXaUJQu7b0FwmGa8jg7rvFlfrkkzL6KSC/Y2KiffTOQNKrl5TLbHpzoHCVObRkiYhR/frBK4dZ3AwwrPjKkCGS0paVJeaoFdSvL/PnrlwpedFFRfbXwYOSlfHkk9Z2oQ8ERl+CgoLIcwsBUv7mze1CYHQkC4eZpnwlEJ3KDCEw01+GSKyB1FTggQdkfKs1a8TaNZt55gvx8ZIKvXu3+X4xgSA1VdzER49K1lRpqTy37jorhhoVggAyZIi8rKRjR3FFOQ4QZ9C2rcylGu44jjUfiRYBIOU2AsY5OeIXDkTHwWDTsqW5AeE8ceiQBGXNxkcuu0yCxo8/Lo2X3FxgxIjqlcETntJMrcKwbjZtkhF/V62SOEU4xgcAFYKIY+pUyaVu1EgG4TJextgxkYCjEESiRQBInGD+fEkTzslxPVFJJNCqlW8Tx7jCU2cyd4wbJ/Gs3/5WemlbER8IJY6ZQ9dfL24hovCMDwAqBBHH5ZfLK5IxhODSS0XEIhHDkpk7V1rEkRYfMGjZUsSspMR/37WnzmTuSEiQ6UCNnsTRJgTNm0sShJE5ZMQHwjUxQoPFStBJSrIP4BapGGWfMUPeI1UIAtGXwB8hACQuMGmSjE569dX+nz8cIRL30I8/SnxgxYrwdQsBKgRKCEhIEL/t6NGhLon/NGsm6Zfr10sv0XbOM21ECIHoS+CvEADS43jnzuAGcoNFSopYBOEeHwDUNaSEiNdeC3UJqk9GhqRAXndd5FZk1Z2y8uxZmWKyOv1WImWQPl9JTRWX28cfyzUac16EI2oRKIqfGO6hSHULATIMSXy8/64hY2iVSMyYshojYDxrlswAGK7xAUCFQFH8xpiAJpxNfm/Ex4uLy1+LwJfOZLGGIQRnzoT/PaJCoCh+0ru3BAONidMjlZYt/bcIVAjc07ChfRgPFQJFiWKMVl8k06qVzKXgaVRbd6gQeCYlJfzjA4AKgaLEPNdfL66hyZN939eX4SVikdGjZTbDhg1DXRLPaNaQosQ4Y8dK7+iJE4HWrYGRI83ve/iwDC3tbUKZWGXYMHmFOyoEihLjEAFvvy1WwahREjMwG/eoTh8CJXxQ15CiKKhRA/jiCxm+5LbbZFpJM6gQRAcqBIqiABA/dlaWzA0wcKC9j4AnVAiiAxUCRVF+oXVrGVX1wAFg8GDJgffEoUMaKI4GVAgURalEly7SG3bVKplRzF1aaXk5cOSIWgTRgAqBoihVGDpU0knnzAFWr3a9zZEjIhIqBJGPKSEgojpEFGf73JaIBhNRorVFUxQllIwdKxlFixa5Xq+dyaIHsxbBUgC1iKg5gP8CuAvAB1YVSlGU0NOkiUym8u23rterEEQPZoWAmPk0gKEA/s7MdwBob12xFEUJB/r2lc5mp05VXae9iqMH00JARF0BjACwwLbM4wjsRPQeER0mok1u1vciohIiWm97TTRfbEVRgkG/fsD588DSpVXXHT4s72oRRD5mhWA8gD8A+JKZNxPRZQC8TXn9AYCbvGyzjJnTba8XTJZFUZQg0b07ULOma/fQoUPSEc3fuY6V8MHUEBPMnA0gGwBsQeMjzDzOyz5LiSi5ugVUFCV0XHAB0KOHeyFo1ix6ZxiLJcxmDX1CRBcSUR0AmwBsIaIJATh/VyLaQEQLiUhjDooShvTtC2zcaI8JGGiv4ujBrGuoHTMfB3ArgIUAWkMyh6rDWgCXMnMHAK8D+MrdhkQ0lohyiSi30Ey/d0VRAka/fvL+3XeVlx8+rIHiaMGsECTa+g3cCmA+M58H4Mc0FnaY+Tgzn7R9zrKdo4mbbWcycwYzZyQlJVXntIqi+Eh6OtCoUVX3kFoE0YNZIfgHgN0A6gBYSkSXAjhenRMT0UVE4l0kos62shRV55iKogSe+HjghhukY5kx3ASzWAQqBNGBKSFg5hnM3JyZB7KwB0BvT/sQ0acAVgC4kojyiWg0Ed1PRPfbNhkGYBMRbQAwA8BwZn8my1MUxWr69QPy84Ht2+X7sWOSVqpCEB2YyhoiovoAJgG43rYoG8ALAErc7cPMv/Z0TGZ+A8Ab5oqpKEoo6dtX3r/9FrjySu1MFm2YdQ29B+AEgF/ZXscBvG9VoRRFCS8uu0yGqDbGHdLOZNGF2akqL2fm2x2+P09E660okKIo4UnfvsDs2UBZmY4zFG2YtQjOEFEP4wsRdQfgZcoKRVGiiX79gOPHgdxcFYJow6xFcD+Af9piBQBwDMA91hRJUZRwpHdv+7DUZ88CcXFA48ahLpUSCMxmDW2wdfxKA5DGzB0B3GBpyRRFCSsch6U+dAhIShIxUCIfn/5GWycwo//AYxaUR1GUMKZvX2DFCmDnTnULRRPV0XMdakpRYgxjWOrsbBWCaKI6QqCdvxQlxjCGpS4vVyGIJjwKARGdIKLjLl4nAFwSpDIqihImGMNSAyoE0YRHIWDmesx8oYtXPWY2m3GkKEoUYYxGqr2KoweN+SuK4hP9+8t7q1ahLYcSOLRVryiKT3TsCCxfDlx7bahLogQKFQJFUXymW7dQl0AJJOoaUhRFiXFUCBRFUWIcFQJFUZQYR4VAURQlxlEhUBRFiXFUCBRFUWIcFQJFUZQYR4VAURQlxlEhUBRFiXFUCBRFUWIcFQJFUZQYR4VAURQlxlEhUBRFiXEsEwIieo+IDhPRJjfriYhmENEOItpIRNdYVRZFURTFPVZaBB8AuMnD+gEA2theYwG8aWFZFEVRFDdYJgTMvBTAUQ+bDAHwTxZWAmhARBdbVR5FURTFNaGMETQHsM/he75tmaIoihJEIiJYTERjiSiXiHILCwtDXRxFUZSoIpRCsB9AS4fvLWzLqsDMM5k5g5kzkpKSglI4RVGUWCGUQjAfwN227KHrAJQwc0EIy6MoihKTWDZ5PRF9CqAXgCZElA9gEoBEAGDmtwBkARgIYAeA0wB+Y1VZFEVRFPdYJgTM/Gsv6xnAQ1adX1EURTFHRASLFUVRFOtQIVAURYlxVAgURVFiHBUCRVGUGEeFQFEUJcZRIVAURYlxVAgURVFiHBUCRVGUGEeFQFEUJcZRIVAURYlxVAgURVFiHBUCRVGUGEeFQFEUJcZRIVAURYlxVAgURVFiHBUCRVGUGEeFQFEUJcZRIVAURYlxVAgURVFiHBUCRVGUGEeFQFEUJcZRIVAURYlxVAgURVFiHBUCRVGUGEeFQFEUJcaxVAiI6CYi2kZEO4joKRfr7yWiQiJab3uNsbI8iqIoSlUSrDowEcUD+BuAfgDyAawhovnMvMVp09nM/LBV5VAURVE8Y6VF0BnADmbeycznAHwGYIiF51MURVH8wEohaA5gn8P3fNsyZ24noo1ENIeIWlpYHkVRFMUFoQ4Wfw0gmZnTACwC8KGrjYhoLBHlElFuYWFhUAuoKIoS7VgpBPsBOLbwW9iW/QIzFzHzWdvXdwB0cnUgZp7JzBnMnJGUlGRJYRVFUWIVK4VgDYA2RNSaiGoAGA5gvuMGRHSxw9fBALZaWB5FURTFBZZlDTFzGRE9DOAbAPEA3mPmzUT0AoBcZp4PYBwRDQZQBuAogHutKo+iKIriGmLmUJfBJzIyMjg3NzfUxVAURYkoiCiPmTNcrQt1sFhRFEUJMSoEiqIoMY4KgaIoSoyjQqAoihLjqBAoiqLEOCoEiqIoMY4KgTuKi4G//hVYuzbUJVEURbEUFQJnjhwBnn0WuPRS4LnngFatQl0iRVEUS1EhMDhxApgwAUhOBv70J6B/f2DZMqBJE+DsWeC114CyslCXMvrZvl1eimdKS4HXXxerNSdHljEDu3bJvawoPhC7QlBRIRXO0qXyvUYNYM4c4NZbgU2bgM8/B9LTZd1XXwHjxwODBgElJcEp3969wLFjwTlXuPDFF8CVV4roKp6ZMAEYNw544gng669lWXExcNllwIUXAqNHA+fOhbaMSuTAzBH16tSpE/vNwoXM48YxZ2Yy163LDDA3b25ff+qU+33ffps5IYH56quZd+ywLz9+nHnBAubHH2dOT2euXZu5fXv7+qlTmceMYZ40ifnQIXPl/Ogj5lq1pGy5uT5dYkRSUcH8178yEzFfcw3z4cOBOea//8189Gj1jxVuzJ8v9+6jjzIXF8uLWe7f999nfvhhWd+3L3NJSUiLqoQPkDHeXNarIa/YfX1VSwjGjZOKuls3eVjefZd53TqpNMzw/ffMjRrJ68ABWfbgg/Iz1qjB3Ls38/jxzE89Zd9n1Cjmiy5ijotjbtKE+dNPvZ9v7lzmXr2YW7VivuAC5s8+8+tyg0pZGfOqVb7vd/68/TccNoz59GlZnpvL/NNP/pfn++/lmJdfzrxzp//HCTfOnmVu2VIaHaWl7rd7/31puHTvbv7+VqIaFQKD48elwqoOP//MfNVVzHl58n3jRuZFi+wVmDs2bWLu3Fl+8qlTq67ftYt59mz794oKsSC6d5d9wt0y+OQTKeeAAfbfxgwHDohQ/v73zOXlsuz0aRHN3r2rV4lNnszcsCFz06bMq1f7f5xgsGkT8zffmNv2xx/NieQ334gVrCisQhB4ysuZz5zxfb/z55mnTbO7iI4dk4ouK0sqrKQkEStHSkvFijAIt9bd1KnMOTnilpgyRawlgPn225k3b3a/3+HD9oq/sLDq+r//XY7jKI7eqKhg/uMfmX/4wb5s61bm5GSxBM1Uim+8IdbE+fPmz1tdCgulfADzb37DfOKE6+22bvX/HP/4B/Pixf7vr0Q8KgThSFkZc9eu4hMnYu7QoXLswRVr18o+u3YFpYheWbJEyv7AA/ZlxcUSD6lXT+IpFRUimsOHM/fpw5yWJhYAwPzMM+6PXVYm7o/mzd1XjI5UVIhLDpB4jSMHDzL36+damNaulUqSWcTMiB01bsx8773M8+Z5t/b8xfG6Pv9cyk/E3LZtVatq1Spx9bz5pu/nOXuWOTWVOTGR+bHHmF97TdyNe/fK+vLy8GtgKAFHhSAcKS9nfv11qXjuvddzoNrg22+Z69cXt8mSJdaX0RMlJdLSvvxy5pMnq64vLJRKllmu9corRcQGD2YePZr5D38Qd4gnli+XW9Qx5uKKigoRFYD5vvvsloa7befOlYo3M1P2adDAfg0nTjDPmcM8YoT81gDzn/8s64qKpFXtbLX5w/z5YgFmZVVevngx8yWXMLdpY3djHj8uv3OrVv4Hv48dYx44kDk+Xq4JEHceM3N2tvwGQ4eK0HhrkMQCgfiPwwwVgnDG15jFtm0So0hIEDdGqFpyo0ZJADwnx9rzPPAA88sve95m4kS5lceM8SwCzOI3NyrC5GRxbR075nrbc+ck/pOfL99nz5b94uKYU1JE0P7xD98q51On5JoAsXi2bKm6zZEjzBs2yOezZ5lvuknOuWyZ+fO4o7xcRHrTJnu5t2+Xa2nVyv7btG5dPVeUlRQWWnvff/CBWGaDB0eVpaRCEG0UFzMPGiR/XygyioyMnKefDv65DXbtkoe0vJz5V78S37o3EWCWfWbNYv7qK99F+NgxacFPmiSVsxEPMbKSZswQy2fgQMmEGjuW+Y477JXJ449LdhnA/MQTnrN+DIyMqkmTfCurP1RUSBD69deZb7vN7hLbvLn6SRaBYv58sWpGj7amkv7+e3GhpaczP/usfXm4iqIPqBBEI+XlzO+8Yw9qBrPlUlbGPHOmtFaDQUUF8xdfSAU+YwbzddfJrbtypaw/fz40FVVFhYiAce4vvpAgeXq6uFqaNpU4ieF2+vxz5gkTfHPr/fijWC3BDF47sn+/xHuGDvUvQSKQrFgh6dRNmsj//+KLgT3+Tz9J0ka7dpWtxKVL5XyDBkns5vx5cSEaz9yhQ5I9aPTnCFNUCKKdgwelcjQqRquoqHDvRrGS8+fFFWO4LTp0kAylgweDX5ZYZNo0+d179gzN/2+wYYOU4eBB5rvuksQDM+JkWI7eePFFids49zspKbGnIhv3IGDvrPf44/K9Zk3pCzN/vrgVwwwVgmhnyxbx6QLS72D6dLtf2xWHDzPv3m3/bsaaOHZMgrZJSeJTDjY//igPo7cAs2INs2aJyyQtTawER8rKxGU2dKg9RXXzZnHfvPkm85o15txg7jh50n6PGu9nz5rrNb1smbjrGjSQWJOnDLCKCntHUVcUF8uz9cILkkBgHGv9eokfjRsnzwcgowuEWXxBhSAWKCqSGzQ1Vf7WhAR7MPDQIcmUefhhe8v67rtl3f79kqHy6quuMyUOHJDOXvXqyX7Dh4ePv1gJLt98w1ynjri3mKUxMXEic4sWcm8kJYlgMMvwHo0b21vPiYnSodLwtZutJI8fZ+7YUbLMXHHqlNzLGzdWXn7ihD2+kpwsMZ0WLaoKQUWFtOid9/eXc+eYv/5aAs7MYokMGCBu3BC71lQIYo2ffrLfiMySvw9Ip6V+/Zj/9Cd7nvqmTczXXy/r69dnfvJJe4uvqEj2iYsTAVi3LvjXooQXmzdLZVdeLn08iKSSnTOnasyookKC+p9/LvdVZqbdj/7SS+Lie+QRaU1v21a1gXH2rNyv8fFV02wN9u2TdNsWLSpbwSdPSsrt+PH2/hpHjtiP26uXDMNhZJxNmVLdX8Y1Bw9KzMgQyueeMz/mWIBRIYh13n1Xett6Cu6uWiUZLnFxEpArKpLlb7+teeWKa779lnnPHv/2nTVLGigXXGC3Gpo2tVsKixcz33mnLH//fc/HWrdO+uOkpUnr3mh5u+ubs3s3c6dO9vPec4+1bpyKCrkeI9OvZs2QDBnjSQhI1kcOGRkZnJubG+piRC87dwJLlgCjRoW6JEoscO6cDPu+YYMMu/7YY7K8Sxdg9Wpg8mTgmWe8H+ebb4Cbbwbi4oCFC4E+fTxvzyzDnuflyQRUNWpU+1JMsW0b8P77wEsvAfHxwMyZMiT+nXcCDRu63+/AAeDgQeCaa/w+NRHlMXOGy3UqBIqihB35+SIMKSkAkbl9VqyQyvSqq6wtWyC56SYRsZo1gSFDgHvvBfr1AxISpFE2ZYo0zLZvB9LSRDD9xJMQWDoxDRHdRETbiGgHET3lYn1NIpptW7+KiJKtLI+iKBFCixZAaqp5EQCArl0jSwQAsV7y8oCxY4HvvgMGDgQeesi+/rPPgLZtgalTxZKwiASrDkxE8QD+BqAfgHwAa4hoPjNvcdhsNIBjzHwFEQ0HMAXAnVaVSVEUJawgEnfPNddIZb9ggX2e9NatgaNHxYVkMVZaBJ0B7GDmncx8DsBnAIY4bTMEwIe2z3MA9CHypQmgKIoSJdSoAdx2G9Cpk3wnCooIANYKQXMA+xy+59uWudyGmcsAlABo7HwgIhpLRLlElFtYWGhRcRVFUWKTiJi8nplnMnMGM2ckJSWFujiKoihRhZVCsB9AS4fvLWzLXG5DRAkA6gMosrBMiqIoihNWCsEaAG2IqDUR1QAwHMB8p23mA7jH9nkYgMUcafmsiqIoEY5lWUPMXEZEDwP4BkA8gPeYeTMRvQDp4TYfwLsAPiKiHQCOQsRCURRFCSKWCQEAMHMWgCynZRMdPpcCuMPKMiiKoiieiYhgsaIoimIdKgSKoigxTsSNNUREhQD2eNmsCYAjQShOuKHXHXvE6rXrdfvOpczsMv8+4oTADESU625wpWhGrzv2iNVr1+sOLOoaUhRFiXFUCBRFUWKcaBWCmaEuQIjQ6449YvXa9boDSFTGCBRFURTzRKtFoCiKopgk6oTA26xo0QIRvUdEh4lok8OyRkS0iIh+tr17mAQ1MiGilkT0PRFtIaLNRPSobXlUXzsR1SKi1US0wXbdz9uWt7bN7rfDNttfkCbfDS5EFE9E64jo37bvUX/dRLSbiH4kovVElGtbZsl9HlVC4DAr2gAA7QD8mojahbZUlvEBgJuclj0F4DtmbgPgO9v3aKMMwOPM3A7AdQAesv3H0X7tZwHcwMwdAKQDuImIroPM6jeNma8AcAwy61808iiArQ7fY+W6ezNzukPKqCX3eVQJAczNihYVMPNSyEB9jjjO+PYhgFuDWqggwMwFzLzW9vkEpHJojii/dhZO2r4m2l4M4AbI7H5AFF43ABBRCwA3A3jH9p0QA9ftBkvu82gTAjOzokUzzZi5wPb5IIBmoSyM1RBRMoCOAFYhBq7d5h5ZD+AwgEUA/geg2Da7HxC99/t0AL8HUGH73hixcd0M4L9ElEdEY23LLLnPLR19VAkdzMxEFLUpYURUF8BcAOOZ+bjjVNfReu3MXA4gnYgaAPgSwFUhLpLlENEgAIeZOY+IeoW6PEGmBzPvJ6KmABYR0U+OKwN5n0ebRWBmVrRo5hARXQwAtvfDIS6PJRBRIkQEZjHzF7bFMXHtAMDMxQC+B9AVQAPb7H5AdN7v3QEMJqLdEFfvDQBeQ/RfN5h5v+39MET4O8Oi+zzahMDMrGjRjOOMb/cAmBfCsliCzT/8LoCtzPyqw6qovnYiSrJZAiCiCwD0g8RHvofM7gdE4XUz8x+YuQUzJ0Oe58XMPAJRft1EVIeI6hmfAfQHsAkW3edR16GMiAZCfIrGrGgvhbhIlkBEnwLoBRmN8BCASQC+AvAvAK0gI7T+ipmdA8oRDRH1ALAMwI+w+4yfhsQJovbaiSgNEhyMhzTg/sXMLxDRZZCWciMA6wCMZOazoSupddhcQ08w86Bov27b9X1p+5oA4BNmfomIGsOC+zzqhEBRFEXxjWhzDSmKoig+okKgKIoS46gQKIqixDgqBIqiKDGOCoGiKEqMo0KgKE4QUbltxEfjFbAB7Igo2XHEWEUJB3SICUWpyhlmTg91IRQlWKhFoCgmsY0P/2fbGPGriegK2/JkIlpMRBuJ6DsiamVb3oyIvrTNIbCBiLrZDhVPRG/b5hX4r62nsKKEDBUCRanKBU6uoTsd1pUwcyqANyA92AHgdQAfMnMagFkAZtiWzwCQbZtD4BoAm23L2wD4GzO3B1AM4HaLr0dRPKI9ixXFCSI6ycx1XSzfDZkcZqdt4LuDzNyYiI4AuJiZz9uWFzBzEyIqBNDCcegD29DZi2wTi4CIngSQyMyTrb8yRXGNWgSK4hvs5rMvOI6JaYOc0gAAALFJREFUUw6N1SkhRoVAUXzjTof3FbbPOZCRMQFgBGRQPECmEnwA+GVSmfrBKqSi+IK2RBSlKhfYZgIz+A8zGymkDYloI6RV/2vbskcAvE9EEwAUAviNbfmjAGYS0WhIy/8BAAVQlDBDYwSKYhJbjCCDmY+EuiyKEkjUNaQoihLjqEWgKIoS46hFoCiKEuOoECiKosQ4KgSKoigxjgqBoihKjKNCoCiKEuOoECiKosQ4/w90giW+5RkfFAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwbfwEbPVr8H"
      },
      "source": [
        "# Making predictions using our trained model\n",
        "predictions = model.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy3xZFU8dYZ7"
      },
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(yte, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_true = [0, 0, 2, 2, 0, 1]\n",
        "y_pred = [0, 0, 2, 2, 0, 2]\n",
        "target_names = ['DoubleMask', 'Single_Mask', 'No_mask']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CIg95hbzFUk",
        "outputId": "017a367d-241b-4888-fd18-4068b2813c1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  DoubleMask     1.0000    1.0000    1.0000         3\n",
            " Single_Mask     0.0000    0.0000    0.0000         1\n",
            "     No_mask     0.6667    1.0000    0.8000         2\n",
            "\n",
            "    accuracy                         0.8333         6\n",
            "   macro avg     0.5556    0.6667    0.6000         6\n",
            "weighted avg     0.7222    0.8333    0.7667         6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuS1EQ1RFhf8"
      },
      "source": [
        "# Lenet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atcJbxF-DKLf"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(224, 224, 3)))\n",
        "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(layers.Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(layers.Dense(120, activation='relu'))\n",
        "model2.add(layers.Dense(84, activation='relu'))\n",
        "model2.add(layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-yuuJ7cDreI"
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0eZV-ChDhyo",
        "outputId": "60c57a0e-be30-40be-ce7a-4cfd743de81b"
      },
      "source": [
        "#steps per epoch=279/30;validation_step=120/30\n",
        "model2.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 13s 741ms/step - loss: 1.5709 - acc: 0.4450 - val_loss: 1.0111 - val_acc: 0.4000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 0.9991 - acc: 0.4398 - val_loss: 0.9352 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.8693 - acc: 0.5524 - val_loss: 0.8366 - val_acc: 0.5929\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.7533 - acc: 0.6283 - val_loss: 0.7694 - val_acc: 0.6571\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 7s 618ms/step - loss: 0.6989 - acc: 0.7068 - val_loss: 0.7989 - val_acc: 0.6500\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 7s 616ms/step - loss: 0.6801 - acc: 0.7094 - val_loss: 0.7672 - val_acc: 0.6929\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.6093 - acc: 0.7539 - val_loss: 0.7744 - val_acc: 0.6929\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 7s 610ms/step - loss: 0.6081 - acc: 0.7435 - val_loss: 0.8548 - val_acc: 0.6500\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 0.6001 - acc: 0.7356 - val_loss: 0.7821 - val_acc: 0.6714\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.5334 - acc: 0.7801 - val_loss: 0.8145 - val_acc: 0.6857\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.5378 - acc: 0.7880 - val_loss: 0.8123 - val_acc: 0.6786\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 630ms/step - loss: 0.4816 - acc: 0.8168 - val_loss: 0.7970 - val_acc: 0.6714\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 624ms/step - loss: 0.4718 - acc: 0.8089 - val_loss: 0.8847 - val_acc: 0.6786\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 8s 654ms/step - loss: 0.4969 - acc: 0.7906 - val_loss: 0.8678 - val_acc: 0.6714\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.4248 - acc: 0.8298 - val_loss: 0.8541 - val_acc: 0.6714\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 610ms/step - loss: 0.3871 - acc: 0.8403 - val_loss: 0.9930 - val_acc: 0.6786\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 0.3411 - acc: 0.8639 - val_loss: 0.9332 - val_acc: 0.7000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 0.3499 - acc: 0.8743 - val_loss: 0.9136 - val_acc: 0.7000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 0.3718 - acc: 0.8403 - val_loss: 1.0374 - val_acc: 0.6571\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 569ms/step - loss: 0.3294 - acc: 0.8639 - val_loss: 1.0304 - val_acc: 0.6714\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 7s 583ms/step - loss: 0.2588 - acc: 0.8979 - val_loss: 1.0396 - val_acc: 0.6500\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 0.2870 - acc: 0.8901 - val_loss: 0.9777 - val_acc: 0.6643\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.2957 - acc: 0.8874 - val_loss: 1.1280 - val_acc: 0.5929\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.2953 - acc: 0.8796 - val_loss: 1.1748 - val_acc: 0.6357\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.2818 - acc: 0.8953 - val_loss: 1.1118 - val_acc: 0.6571\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 7s 600ms/step - loss: 0.1725 - acc: 0.9398 - val_loss: 1.2802 - val_acc: 0.6571\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.1732 - acc: 0.9319 - val_loss: 1.2253 - val_acc: 0.6714\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 7s 609ms/step - loss: 0.1653 - acc: 0.9424 - val_loss: 1.2303 - val_acc: 0.6857\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 595ms/step - loss: 0.1422 - acc: 0.9607 - val_loss: 1.2893 - val_acc: 0.6500\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.1287 - acc: 0.9450 - val_loss: 1.4456 - val_acc: 0.6571\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 0.1111 - acc: 0.9503 - val_loss: 1.3827 - val_acc: 0.6929\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 0.1305 - acc: 0.9555 - val_loss: 1.7090 - val_acc: 0.6643\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 592ms/step - loss: 0.2367 - acc: 0.9162 - val_loss: 1.3336 - val_acc: 0.6500\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.1299 - acc: 0.9581 - val_loss: 1.4598 - val_acc: 0.6571\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 0.1671 - acc: 0.9476 - val_loss: 1.4586 - val_acc: 0.6286\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 0.1484 - acc: 0.9555 - val_loss: 1.3536 - val_acc: 0.6643\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 578ms/step - loss: 0.1260 - acc: 0.9555 - val_loss: 1.7475 - val_acc: 0.6500\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.1473 - acc: 0.9503 - val_loss: 1.5526 - val_acc: 0.6214\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 0.1573 - acc: 0.9476 - val_loss: 1.3493 - val_acc: 0.6643\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 7s 604ms/step - loss: 0.1279 - acc: 0.9581 - val_loss: 1.5553 - val_acc: 0.6500\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 616ms/step - loss: 0.1847 - acc: 0.9398 - val_loss: 1.5832 - val_acc: 0.6643\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 584ms/step - loss: 0.1616 - acc: 0.9293 - val_loss: 1.4497 - val_acc: 0.6929\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 7s 577ms/step - loss: 0.1625 - acc: 0.9503 - val_loss: 1.4385 - val_acc: 0.6714\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 0.1239 - acc: 0.9476 - val_loss: 1.3834 - val_acc: 0.6929\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 0.1071 - acc: 0.9634 - val_loss: 1.4634 - val_acc: 0.6714\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 7s 575ms/step - loss: 0.0666 - acc: 0.9764 - val_loss: 1.4500 - val_acc: 0.7000\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 7s 571ms/step - loss: 0.0430 - acc: 0.9869 - val_loss: 1.6807 - val_acc: 0.6571\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 7s 579ms/step - loss: 0.0415 - acc: 0.9895 - val_loss: 2.2872 - val_acc: 0.6429\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 7s 582ms/step - loss: 0.0391 - acc: 0.9895 - val_loss: 1.8764 - val_acc: 0.6571\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 573ms/step - loss: 0.0422 - acc: 0.9843 - val_loss: 2.0313 - val_acc: 0.6571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81b01b4f90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lenet_1**"
      ],
      "metadata": {
        "id": "KGPM2x-Pq7iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model21 = Sequential()\n",
        "model21.add(layers.Conv2D(3, kernel_size=(4, 4), activation='sigmoid', input_shape=(224, 224, 3)))\n",
        "model21.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model21.add(layers.Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
        "model21.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model21.add(Flatten())\n",
        "model21.add(layers.Dense(120, activation='relu'))\n",
        "model21.add(layers.Dense(84, activation='relu'))\n",
        "model21.add(layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "q2R8LQlBq5mc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model21.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='adagrad',\n",
        "\t      metrics=['acc'])"
      ],
      "metadata": {
        "id": "LOo1GvUYrT7p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model21.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKk6r_fVrXdQ",
        "outputId": "d644f050-e473-43cb-ca52-c16622f28129"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 8s 625ms/step - loss: 1.0750 - acc: 0.4555 - val_loss: 1.0229 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 7s 578ms/step - loss: 1.0406 - acc: 0.4817 - val_loss: 1.0226 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 7s 585ms/step - loss: 1.0452 - acc: 0.4660 - val_loss: 1.0242 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 581ms/step - loss: 1.0450 - acc: 0.4817 - val_loss: 1.0211 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 7s 606ms/step - loss: 1.0390 - acc: 0.4817 - val_loss: 1.0210 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 7s 585ms/step - loss: 1.0564 - acc: 0.4634 - val_loss: 1.0200 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 572ms/step - loss: 1.0362 - acc: 0.4817 - val_loss: 1.0190 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 7s 579ms/step - loss: 1.0374 - acc: 0.4817 - val_loss: 1.0215 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 7s 575ms/step - loss: 1.0365 - acc: 0.4817 - val_loss: 1.0205 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 1.0411 - acc: 0.4817 - val_loss: 1.0250 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 1.0391 - acc: 0.4817 - val_loss: 1.0202 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 573ms/step - loss: 1.0365 - acc: 0.4817 - val_loss: 1.0198 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 576ms/step - loss: 1.0389 - acc: 0.4817 - val_loss: 1.0196 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 1.0388 - acc: 0.4817 - val_loss: 1.0372 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 1.0382 - acc: 0.4817 - val_loss: 1.0206 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 1.0359 - acc: 0.4817 - val_loss: 1.0207 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 581ms/step - loss: 1.0374 - acc: 0.4817 - val_loss: 1.0197 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 1.0354 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 7s 575ms/step - loss: 1.0366 - acc: 0.4817 - val_loss: 1.0189 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 1.0358 - acc: 0.4817 - val_loss: 1.0188 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 7s 571ms/step - loss: 1.0359 - acc: 0.4817 - val_loss: 1.0191 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 7s 572ms/step - loss: 1.0340 - acc: 0.4817 - val_loss: 1.0188 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 1.0372 - acc: 0.4817 - val_loss: 1.0189 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 1.0369 - acc: 0.4817 - val_loss: 1.0192 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 7s 584ms/step - loss: 1.0365 - acc: 0.4817 - val_loss: 1.0196 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 7s 572ms/step - loss: 1.0346 - acc: 0.4817 - val_loss: 1.0189 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 8s 652ms/step - loss: 1.0381 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 1.0366 - acc: 0.4817 - val_loss: 1.0188 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 587ms/step - loss: 1.0357 - acc: 0.4817 - val_loss: 1.0209 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 1.0346 - acc: 0.4817 - val_loss: 1.0206 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 1.0350 - acc: 0.4817 - val_loss: 1.0191 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 1.0369 - acc: 0.4817 - val_loss: 1.0190 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 581ms/step - loss: 1.0361 - acc: 0.4817 - val_loss: 1.0215 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 1.0410 - acc: 0.4817 - val_loss: 1.0206 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 579ms/step - loss: 1.0347 - acc: 0.4817 - val_loss: 1.0188 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 1.0373 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 604ms/step - loss: 1.0371 - acc: 0.4817 - val_loss: 1.0202 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 588ms/step - loss: 1.0356 - acc: 0.4817 - val_loss: 1.0208 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 1.0358 - acc: 0.4817 - val_loss: 1.0201 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 1.0367 - acc: 0.4817 - val_loss: 1.0189 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 1.0363 - acc: 0.4817 - val_loss: 1.0190 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 1.0355 - acc: 0.4817 - val_loss: 1.0192 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 7s 586ms/step - loss: 1.0355 - acc: 0.4817 - val_loss: 1.0240 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 1.0353 - acc: 0.4817 - val_loss: 1.0206 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 1.0330 - acc: 0.4817 - val_loss: 1.0188 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 7s 600ms/step - loss: 1.0354 - acc: 0.4817 - val_loss: 1.0190 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 1.0364 - acc: 0.4817 - val_loss: 1.0223 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 1.0369 - acc: 0.4817 - val_loss: 1.0210 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 7s 600ms/step - loss: 1.0342 - acc: 0.4817 - val_loss: 1.0245 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 1.0377 - acc: 0.4817 - val_loss: 1.0200 - val_acc: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f812a24ae10>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lenet_2**"
      ],
      "metadata": {
        "id": "3I0G9viKsDTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model22 = Sequential()\n",
        "model22.add(layers.Conv2D(10, kernel_size=(6, 6), activation='tanh', input_shape=(224, 224, 3)))\n",
        "model22.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model22.add(layers.Conv2D(64, kernel_size=(3, 3), activation='tanh'))\n",
        "model22.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model22.add(Flatten())\n",
        "model22.add(layers.Dense(180, activation='relu'))\n",
        "model22.add(layers.Dense(84, activation='relu'))\n",
        "model22.add(layers.Dense(3, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "dJPaIu0VsGh9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model22.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='RmsProp',\n",
        "\t      metrics=['acc'])"
      ],
      "metadata": {
        "id": "WU9fXQtksovb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model22.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyQUkusDssr_",
        "outputId": "81ea3949-5ed9-40a5-c13d-3ee9613b7444"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 9s 614ms/step - loss: 26.9295 - acc: 0.2932 - val_loss: 1.5866 - val_acc: 0.4643\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 1.1441 - acc: 0.5707 - val_loss: 2.0883 - val_acc: 0.5357\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 8s 646ms/step - loss: 6.6391 - acc: 0.4084 - val_loss: 1.8461 - val_acc: 0.5929\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 1.5291 - acc: 0.5419 - val_loss: 0.8512 - val_acc: 0.5643\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 7s 630ms/step - loss: 0.7349 - acc: 0.6623 - val_loss: 1.0146 - val_acc: 0.6571\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 1.1018 - acc: 0.6230 - val_loss: 10.0040 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 593ms/step - loss: 12.5551 - acc: 0.4136 - val_loss: 16.4875 - val_acc: 0.5429\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 3.4442 - acc: 0.5131 - val_loss: 3.3834 - val_acc: 0.6000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.9852 - acc: 0.6728 - val_loss: 0.7507 - val_acc: 0.6214\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 2.0242 - acc: 0.5785 - val_loss: 7.0131 - val_acc: 0.3429\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 2.3705 - acc: 0.4712 - val_loss: 0.9617 - val_acc: 0.6071\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 1.4284 - acc: 0.5995 - val_loss: 1.8061 - val_acc: 0.6143\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 0.8290 - acc: 0.6806 - val_loss: 0.7926 - val_acc: 0.6357\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 2.9223 - acc: 0.5314 - val_loss: 12.8090 - val_acc: 0.1857\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 3.6240 - acc: 0.5157 - val_loss: 0.7918 - val_acc: 0.6429\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 606ms/step - loss: 0.6434 - acc: 0.7251 - val_loss: 1.1034 - val_acc: 0.6643\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 616ms/step - loss: 2.1321 - acc: 0.6387 - val_loss: 2.8561 - val_acc: 0.4143\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 2.5796 - acc: 0.5288 - val_loss: 1.0545 - val_acc: 0.7000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.7084 - acc: 0.7016 - val_loss: 0.8674 - val_acc: 0.6929\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 1.1299 - acc: 0.7068 - val_loss: 2.1113 - val_acc: 0.5929\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 1.5954 - acc: 0.6492 - val_loss: 1.0282 - val_acc: 0.5286\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 7s 579ms/step - loss: 1.2783 - acc: 0.6806 - val_loss: 3.8272 - val_acc: 0.4071\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 591ms/step - loss: 1.6823 - acc: 0.5812 - val_loss: 0.7686 - val_acc: 0.6357\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 0.6376 - acc: 0.7382 - val_loss: 0.8180 - val_acc: 0.6000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 1.0767 - acc: 0.6047 - val_loss: 1.5733 - val_acc: 0.6143\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 8s 673ms/step - loss: 0.9166 - acc: 0.6571 - val_loss: 0.7515 - val_acc: 0.6929\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 7s 593ms/step - loss: 0.5707 - acc: 0.7670 - val_loss: 0.9298 - val_acc: 0.5500\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 1.4038 - acc: 0.6309 - val_loss: 1.4117 - val_acc: 0.3929\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 605ms/step - loss: 0.6726 - acc: 0.7120 - val_loss: 0.7842 - val_acc: 0.6714\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.7182 - acc: 0.7618 - val_loss: 2.0846 - val_acc: 0.4643\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 8s 626ms/step - loss: 1.1247 - acc: 0.6937 - val_loss: 1.3160 - val_acc: 0.4357\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.4423 - acc: 0.8063 - val_loss: 0.8895 - val_acc: 0.7214\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 1.5273 - acc: 0.6126 - val_loss: 1.3362 - val_acc: 0.5929\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 7s 600ms/step - loss: 0.5601 - acc: 0.7513 - val_loss: 0.9888 - val_acc: 0.6429\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 590ms/step - loss: 0.5054 - acc: 0.7775 - val_loss: 1.1845 - val_acc: 0.5357\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 7s 583ms/step - loss: 0.6071 - acc: 0.7565 - val_loss: 0.9499 - val_acc: 0.6286\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 574ms/step - loss: 1.4967 - acc: 0.6859 - val_loss: 0.9955 - val_acc: 0.6571\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 595ms/step - loss: 0.3450 - acc: 0.8586 - val_loss: 1.0284 - val_acc: 0.6929\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 7s 599ms/step - loss: 0.4336 - acc: 0.8560 - val_loss: 1.1940 - val_acc: 0.6286\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 7s 609ms/step - loss: 0.8101 - acc: 0.7513 - val_loss: 1.2849 - val_acc: 0.6429\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.4071 - acc: 0.8325 - val_loss: 1.0354 - val_acc: 0.6357\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 631ms/step - loss: 0.8609 - acc: 0.7696 - val_loss: 2.2711 - val_acc: 0.4429\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 0.5152 - acc: 0.8063 - val_loss: 1.1406 - val_acc: 0.5357\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 623ms/step - loss: 0.5012 - acc: 0.8115 - val_loss: 1.6943 - val_acc: 0.6000\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 0.4500 - acc: 0.8272 - val_loss: 0.8796 - val_acc: 0.6714\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 7s 598ms/step - loss: 0.2480 - acc: 0.9162 - val_loss: 1.3886 - val_acc: 0.6786\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 1.2388 - acc: 0.6911 - val_loss: 1.0154 - val_acc: 0.6571\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.3053 - acc: 0.8927 - val_loss: 0.9615 - val_acc: 0.6857\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.2528 - acc: 0.9058 - val_loss: 1.2142 - val_acc: 0.6643\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 605ms/step - loss: 0.5452 - acc: 0.8613 - val_loss: 1.9071 - val_acc: 0.4286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f812a103150>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lenet_3**"
      ],
      "metadata": {
        "id": "UuePCIvguk9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model23 = Sequential()\n",
        "model23.add(layers.Conv2D(32, kernel_size=(8, 8), activation='tanh', input_shape=(224, 224, 3)))\n",
        "model23.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model23.add(layers.Conv2D(120, kernel_size=(8, 8), activation='tanh'))\n",
        "model23.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model23.add(Flatten())\n",
        "model23.add(layers.Dense(240, activation='sigmoid'))\n",
        "model23.add(layers.Dense(84, activation='sigmoid'))\n",
        "model23.add(layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "_w9AKDmQuklx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model23.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='Adadelta',\n",
        "\t      metrics=['acc'])"
      ],
      "metadata": {
        "id": "ESEuCVY7uxi_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we used optimizer as adadelta.And we observed that from the starting to ending all the epochs recorded with same accuracy."
      ],
      "metadata": {
        "id": "QP-o4QkyhtPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model23.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7inoEnfYu0QB",
        "outputId": "da4f2cc1-8b27-4b25-f193-7ebc38451127"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 11s 751ms/step - loss: 1.0515 - acc: 0.4817 - val_loss: 1.0400 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 8s 636ms/step - loss: 1.0452 - acc: 0.4817 - val_loss: 1.0334 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 8s 644ms/step - loss: 1.0397 - acc: 0.4817 - val_loss: 1.0282 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 629ms/step - loss: 1.0351 - acc: 0.4817 - val_loss: 1.0240 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 7s 622ms/step - loss: 1.0328 - acc: 0.4817 - val_loss: 1.0207 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 8s 652ms/step - loss: 1.0297 - acc: 0.4817 - val_loss: 1.0181 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 8s 646ms/step - loss: 1.0279 - acc: 0.4817 - val_loss: 1.0159 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 8s 641ms/step - loss: 1.0272 - acc: 0.4817 - val_loss: 1.0141 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 8s 641ms/step - loss: 1.0250 - acc: 0.4817 - val_loss: 1.0126 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 1.0244 - acc: 0.4817 - val_loss: 1.0113 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 7s 626ms/step - loss: 1.0226 - acc: 0.4817 - val_loss: 1.0102 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 626ms/step - loss: 1.0220 - acc: 0.4817 - val_loss: 1.0091 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 1.0207 - acc: 0.4817 - val_loss: 1.0081 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 1.0208 - acc: 0.4817 - val_loss: 1.0074 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 1.0201 - acc: 0.4817 - val_loss: 1.0067 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 1.0194 - acc: 0.4817 - val_loss: 1.0060 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 632ms/step - loss: 1.0179 - acc: 0.4817 - val_loss: 1.0053 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 9s 738ms/step - loss: 1.0177 - acc: 0.4817 - val_loss: 1.0046 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 9s 717ms/step - loss: 1.0179 - acc: 0.4817 - val_loss: 1.0041 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 8s 633ms/step - loss: 1.0176 - acc: 0.4817 - val_loss: 1.0035 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 8s 630ms/step - loss: 1.0155 - acc: 0.4817 - val_loss: 1.0029 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 1.0158 - acc: 0.4817 - val_loss: 1.0023 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 1.0144 - acc: 0.4817 - val_loss: 1.0017 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 7s 628ms/step - loss: 1.0144 - acc: 0.4817 - val_loss: 1.0012 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 7s 618ms/step - loss: 1.0128 - acc: 0.4817 - val_loss: 1.0006 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 8s 642ms/step - loss: 1.0122 - acc: 0.4817 - val_loss: 1.0000 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 1.0132 - acc: 0.4817 - val_loss: 0.9995 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 8s 616ms/step - loss: 1.0129 - acc: 0.4817 - val_loss: 0.9990 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 1.0126 - acc: 0.4817 - val_loss: 0.9985 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 612ms/step - loss: 1.0107 - acc: 0.4817 - val_loss: 0.9979 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 7s 622ms/step - loss: 1.0108 - acc: 0.4817 - val_loss: 0.9973 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 8s 631ms/step - loss: 1.0115 - acc: 0.4817 - val_loss: 0.9968 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 8s 677ms/step - loss: 1.0102 - acc: 0.4817 - val_loss: 0.9963 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 7s 624ms/step - loss: 1.0087 - acc: 0.4817 - val_loss: 0.9957 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 1.0087 - acc: 0.4817 - val_loss: 0.9952 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 8s 634ms/step - loss: 1.0084 - acc: 0.4817 - val_loss: 0.9946 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 624ms/step - loss: 1.0082 - acc: 0.4817 - val_loss: 0.9941 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 1.0057 - acc: 0.4817 - val_loss: 0.9935 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 1.0053 - acc: 0.4817 - val_loss: 0.9929 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 1.0057 - acc: 0.4817 - val_loss: 0.9923 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 1.0039 - acc: 0.4817 - val_loss: 0.9918 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 1.0029 - acc: 0.4817 - val_loss: 0.9911 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 8s 652ms/step - loss: 1.0042 - acc: 0.4817 - val_loss: 0.9905 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 609ms/step - loss: 1.0027 - acc: 0.4817 - val_loss: 0.9899 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 617ms/step - loss: 1.0017 - acc: 0.4817 - val_loss: 0.9893 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 7s 615ms/step - loss: 1.0003 - acc: 0.4817 - val_loss: 0.9887 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 8s 667ms/step - loss: 1.0016 - acc: 0.4817 - val_loss: 0.9881 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 8s 627ms/step - loss: 1.0010 - acc: 0.4817 - val_loss: 0.9875 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 1.0004 - acc: 0.4817 - val_loss: 0.9870 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 0.9977 - acc: 0.4817 - val_loss: 0.9863 - val_acc: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81186b8190>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lenet_4**"
      ],
      "metadata": {
        "id": "O_LfXMCCyEH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model24 = Sequential()\n",
        "model24.add(layers.Conv2D(12, kernel_size=(8, 8), activation='softmax', input_shape=(224, 224, 3)))\n",
        "model24.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model24.add(layers.Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n",
        "model24.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model24.add(Flatten())\n",
        "model24.add(layers.Dense(140, activation='relu'))\n",
        "model24.add(layers.Dense(64, activation='tanh'))\n",
        "model24.add(layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "2ooUk0bQyIv1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model24.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='RmsProp',\n",
        "\t      metrics=['acc'])"
      ],
      "metadata": {
        "id": "K6rP3s_wy6Yh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model23.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGJDL7Hdy9_5",
        "outputId": "14cb6c4d-64b9-4220-cc82-fac2211b75db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 0.9727 - acc: 0.4817 - val_loss: 0.9619 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 8s 636ms/step - loss: 0.9727 - acc: 0.4817 - val_loss: 0.9608 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 8s 653ms/step - loss: 0.9732 - acc: 0.4817 - val_loss: 0.9599 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.9695 - acc: 0.4817 - val_loss: 0.9590 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 8s 632ms/step - loss: 0.9704 - acc: 0.4817 - val_loss: 0.9580 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 8s 633ms/step - loss: 0.9673 - acc: 0.4817 - val_loss: 0.9569 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 617ms/step - loss: 0.9657 - acc: 0.4817 - val_loss: 0.9559 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 8s 640ms/step - loss: 0.9668 - acc: 0.4817 - val_loss: 0.9552 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 0.9632 - acc: 0.4817 - val_loss: 0.9542 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.9651 - acc: 0.4843 - val_loss: 0.9532 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 7s 623ms/step - loss: 0.9677 - acc: 0.4817 - val_loss: 0.9524 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.9663 - acc: 0.4843 - val_loss: 0.9516 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 630ms/step - loss: 0.9639 - acc: 0.4843 - val_loss: 0.9506 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 8s 640ms/step - loss: 0.9609 - acc: 0.4817 - val_loss: 0.9498 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 7s 615ms/step - loss: 0.9633 - acc: 0.4817 - val_loss: 0.9489 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 605ms/step - loss: 0.9589 - acc: 0.4843 - val_loss: 0.9480 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.9618 - acc: 0.4843 - val_loss: 0.9471 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 7s 604ms/step - loss: 0.9565 - acc: 0.4895 - val_loss: 0.9462 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 7s 615ms/step - loss: 0.9577 - acc: 0.4843 - val_loss: 0.9451 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 0.9568 - acc: 0.4895 - val_loss: 0.9443 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.9528 - acc: 0.4895 - val_loss: 0.9431 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 0.9502 - acc: 0.4895 - val_loss: 0.9419 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.9548 - acc: 0.4948 - val_loss: 0.9409 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.9540 - acc: 0.4869 - val_loss: 0.9400 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 8s 634ms/step - loss: 0.9492 - acc: 0.4974 - val_loss: 0.9390 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 8s 640ms/step - loss: 0.9491 - acc: 0.4974 - val_loss: 0.9381 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 7s 618ms/step - loss: 0.9470 - acc: 0.4948 - val_loss: 0.9373 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 7s 607ms/step - loss: 0.9455 - acc: 0.5052 - val_loss: 0.9361 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 0.9471 - acc: 0.5000 - val_loss: 0.9350 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 612ms/step - loss: 0.9467 - acc: 0.5026 - val_loss: 0.9341 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 8s 625ms/step - loss: 0.9413 - acc: 0.5026 - val_loss: 0.9332 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 7s 624ms/step - loss: 0.9433 - acc: 0.4948 - val_loss: 0.9321 - val_acc: 0.5071\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 0.9432 - acc: 0.5026 - val_loss: 0.9313 - val_acc: 0.5143\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 7s 626ms/step - loss: 0.9441 - acc: 0.5079 - val_loss: 0.9302 - val_acc: 0.5143\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 0.9430 - acc: 0.5052 - val_loss: 0.9295 - val_acc: 0.5143\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 7s 617ms/step - loss: 0.9391 - acc: 0.5131 - val_loss: 0.9283 - val_acc: 0.5143\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.9418 - acc: 0.5026 - val_loss: 0.9272 - val_acc: 0.5143\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.9346 - acc: 0.5105 - val_loss: 0.9264 - val_acc: 0.5214\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 8s 645ms/step - loss: 0.9330 - acc: 0.5105 - val_loss: 0.9253 - val_acc: 0.5214\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 8s 653ms/step - loss: 0.9347 - acc: 0.5131 - val_loss: 0.9243 - val_acc: 0.5214\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.9342 - acc: 0.5079 - val_loss: 0.9232 - val_acc: 0.5214\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 606ms/step - loss: 0.9355 - acc: 0.5105 - val_loss: 0.9223 - val_acc: 0.5214\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 7s 617ms/step - loss: 0.9299 - acc: 0.5157 - val_loss: 0.9211 - val_acc: 0.5214\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.9282 - acc: 0.5157 - val_loss: 0.9203 - val_acc: 0.5286\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 606ms/step - loss: 0.9298 - acc: 0.5131 - val_loss: 0.9195 - val_acc: 0.5429\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 0.9271 - acc: 0.5131 - val_loss: 0.9184 - val_acc: 0.5357\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.9257 - acc: 0.5340 - val_loss: 0.9169 - val_acc: 0.5357\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.9250 - acc: 0.5209 - val_loss: 0.9163 - val_acc: 0.5357\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 7s 628ms/step - loss: 0.9258 - acc: 0.5314 - val_loss: 0.9152 - val_acc: 0.5357\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 8s 646ms/step - loss: 0.9276 - acc: 0.5209 - val_loss: 0.9144 - val_acc: 0.5357\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81183b2410>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lenet_5**"
      ],
      "metadata": {
        "id": "4NScIZrEzG4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model25 = Sequential()\n",
        "model25.add(layers.Conv2D(20, kernel_size=(18, 18), activation='softmax', input_shape=(224, 224, 3)))\n",
        "model25.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model25.add(layers.Conv2D(32, kernel_size=(5, 5), activation='relu'))\n",
        "model25.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model25.add(Flatten())\n",
        "model25.add(layers.Dense(220, activation='relu'))\n",
        "model25.add(layers.Dense(124, activation='relu'))\n",
        "model25.add(layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "Ns2Iq6qIzJtx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model25.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc'])"
      ],
      "metadata": {
        "id": "O29cXzfVzaDz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model25.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhj0iCQRzcov",
        "outputId": "d4381b1d-717c-4f51-d666-39d804a14b95"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 10s 659ms/step - loss: 1.4751 - acc: 0.4476 - val_loss: 0.9593 - val_acc: 0.5429\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 7s 599ms/step - loss: 1.0253 - acc: 0.4948 - val_loss: 1.1110 - val_acc: 0.3714\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 7s 615ms/step - loss: 0.9876 - acc: 0.5026 - val_loss: 0.9033 - val_acc: 0.6429\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 7s 612ms/step - loss: 0.9039 - acc: 0.5995 - val_loss: 0.8824 - val_acc: 0.6214\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 0.8738 - acc: 0.6126 - val_loss: 0.8095 - val_acc: 0.6429\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 7s 614ms/step - loss: 0.8435 - acc: 0.6047 - val_loss: 0.8464 - val_acc: 0.6286\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 7s 610ms/step - loss: 0.7837 - acc: 0.6518 - val_loss: 0.7794 - val_acc: 0.6500\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 0.7834 - acc: 0.6283 - val_loss: 0.8098 - val_acc: 0.6643\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.7198 - acc: 0.6675 - val_loss: 0.7847 - val_acc: 0.6643\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 7s 632ms/step - loss: 0.7202 - acc: 0.6859 - val_loss: 0.8147 - val_acc: 0.6071\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.6956 - acc: 0.6963 - val_loss: 0.7953 - val_acc: 0.6571\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.6568 - acc: 0.7068 - val_loss: 0.7613 - val_acc: 0.6429\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 0.6239 - acc: 0.7435 - val_loss: 0.8016 - val_acc: 0.6714\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 7s 616ms/step - loss: 0.5872 - acc: 0.7539 - val_loss: 0.8440 - val_acc: 0.6286\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.5990 - acc: 0.7539 - val_loss: 0.8240 - val_acc: 0.6000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 7s 609ms/step - loss: 0.5993 - acc: 0.7461 - val_loss: 0.7521 - val_acc: 0.6929\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 7s 593ms/step - loss: 0.5623 - acc: 0.7461 - val_loss: 0.7603 - val_acc: 0.7214\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 7s 623ms/step - loss: 0.4702 - acc: 0.8141 - val_loss: 0.8147 - val_acc: 0.7000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 7s 615ms/step - loss: 0.5098 - acc: 0.7984 - val_loss: 0.9037 - val_acc: 0.5571\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 7s 612ms/step - loss: 0.4944 - acc: 0.7958 - val_loss: 0.8452 - val_acc: 0.6857\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 7s 599ms/step - loss: 0.5479 - acc: 0.7644 - val_loss: 0.8476 - val_acc: 0.6357\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 0.4747 - acc: 0.8010 - val_loss: 0.7995 - val_acc: 0.6500\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 7s 612ms/step - loss: 0.3866 - acc: 0.8403 - val_loss: 0.8316 - val_acc: 0.6571\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 7s 608ms/step - loss: 0.3756 - acc: 0.8639 - val_loss: 0.9274 - val_acc: 0.6000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 7s 625ms/step - loss: 0.3851 - acc: 0.8455 - val_loss: 0.9042 - val_acc: 0.6500\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 7s 605ms/step - loss: 0.3679 - acc: 0.8691 - val_loss: 1.0128 - val_acc: 0.6857\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.3386 - acc: 0.8717 - val_loss: 1.0279 - val_acc: 0.6571\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 8s 673ms/step - loss: 0.2756 - acc: 0.8822 - val_loss: 1.1761 - val_acc: 0.6357\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 0.2783 - acc: 0.9058 - val_loss: 0.9374 - val_acc: 0.6429\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 7s 603ms/step - loss: 0.2218 - acc: 0.9136 - val_loss: 1.3351 - val_acc: 0.6857\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 7s 611ms/step - loss: 0.2236 - acc: 0.9215 - val_loss: 1.0985 - val_acc: 0.6286\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 7s 606ms/step - loss: 0.1854 - acc: 0.9424 - val_loss: 1.3848 - val_acc: 0.5571\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 0.1983 - acc: 0.9188 - val_loss: 1.3873 - val_acc: 0.6500\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 8s 634ms/step - loss: 0.2102 - acc: 0.9319 - val_loss: 1.4753 - val_acc: 0.6214\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 7s 615ms/step - loss: 0.1809 - acc: 0.9372 - val_loss: 1.0682 - val_acc: 0.6786\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 7s 617ms/step - loss: 0.1931 - acc: 0.9398 - val_loss: 1.1908 - val_acc: 0.6500\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 7s 613ms/step - loss: 0.1914 - acc: 0.9319 - val_loss: 1.1879 - val_acc: 0.6357\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 7s 597ms/step - loss: 0.1350 - acc: 0.9581 - val_loss: 1.2673 - val_acc: 0.6429\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.1014 - acc: 0.9634 - val_loss: 1.2841 - val_acc: 0.6000\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 7s 602ms/step - loss: 0.1560 - acc: 0.9476 - val_loss: 1.4018 - val_acc: 0.6429\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 7s 593ms/step - loss: 0.2191 - acc: 0.9241 - val_loss: 1.4282 - val_acc: 0.5714\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 7s 604ms/step - loss: 0.1594 - acc: 0.9450 - val_loss: 1.0382 - val_acc: 0.6643\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 7s 630ms/step - loss: 0.1507 - acc: 0.9476 - val_loss: 1.0944 - val_acc: 0.6357\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 7s 610ms/step - loss: 0.0858 - acc: 0.9738 - val_loss: 1.1746 - val_acc: 0.6714\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 0.0579 - acc: 0.9817 - val_loss: 1.1718 - val_acc: 0.6786\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 8s 632ms/step - loss: 0.0763 - acc: 0.9791 - val_loss: 1.3281 - val_acc: 0.6500\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 7s 622ms/step - loss: 0.0642 - acc: 0.9791 - val_loss: 1.1988 - val_acc: 0.6929\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 8s 637ms/step - loss: 0.0328 - acc: 0.9921 - val_loss: 1.2856 - val_acc: 0.7000\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 8s 639ms/step - loss: 0.0237 - acc: 0.9974 - val_loss: 1.2936 - val_acc: 0.6500\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 7s 622ms/step - loss: 0.0185 - acc: 0.9948 - val_loss: 1.3884 - val_acc: 0.6571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81182b2290>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv2fRHt3Far6"
      },
      "source": [
        "**Making Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XBPNR4REMPX"
      },
      "source": [
        "# Making predictions using our trained model\n",
        "predictions2 = model2.predict(x_test)\n",
        "predictions2 = np.argmax(predictions2, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oONGE2Mw1g-j"
      },
      "source": [
        "# VGGNet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAW-zDyu1g-w"
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model3.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model3.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model3.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model3.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(units=4096,activation=\"relu\"))\n",
        "model3.add(Dense(units=4096,activation=\"relu\"))\n",
        "model3.add(Dense(units=3, activation=\"softmax\"))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5_fj1Ty1g-x"
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6663008f-2f52-46c8-b078-56016dab1b44",
        "id": "gSSd1uvp1g-x"
      },
      "source": [
        "#steps per epoch=279/30;validation_step=120/30\n",
        "model3.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 23s 1s/step - loss: 1.2929 - acc: 0.4607 - val_loss: 1.0839 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 9s 763ms/step - loss: 1.0758 - acc: 0.4817 - val_loss: 1.0307 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 9s 733ms/step - loss: 1.0398 - acc: 0.4817 - val_loss: 1.0211 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 9s 751ms/step - loss: 1.0388 - acc: 0.4817 - val_loss: 1.0222 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 9s 776ms/step - loss: 1.0333 - acc: 0.4817 - val_loss: 1.0190 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 9s 774ms/step - loss: 1.0352 - acc: 0.4817 - val_loss: 1.0236 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 9s 747ms/step - loss: 1.0414 - acc: 0.4817 - val_loss: 1.0287 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 9s 746ms/step - loss: 1.0371 - acc: 0.4817 - val_loss: 1.0193 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 9s 740ms/step - loss: 1.0342 - acc: 0.4817 - val_loss: 1.0211 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 9s 736ms/step - loss: 1.0341 - acc: 0.4817 - val_loss: 1.0214 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 9s 737ms/step - loss: 1.0346 - acc: 0.4817 - val_loss: 1.0193 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 9s 741ms/step - loss: 1.0352 - acc: 0.4817 - val_loss: 1.0201 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 9s 753ms/step - loss: 1.0360 - acc: 0.4817 - val_loss: 1.0237 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 9s 767ms/step - loss: 1.0334 - acc: 0.4817 - val_loss: 1.0194 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 9s 745ms/step - loss: 1.0345 - acc: 0.4817 - val_loss: 1.0192 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 9s 764ms/step - loss: 1.0330 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 9s 745ms/step - loss: 1.0346 - acc: 0.4817 - val_loss: 1.0226 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 9s 742ms/step - loss: 1.0339 - acc: 0.4817 - val_loss: 1.0194 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 9s 762ms/step - loss: 1.0376 - acc: 0.4817 - val_loss: 1.0193 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 9s 746ms/step - loss: 1.0353 - acc: 0.4817 - val_loss: 1.0256 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 9s 745ms/step - loss: 1.0355 - acc: 0.4817 - val_loss: 1.0205 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 9s 734ms/step - loss: 1.0340 - acc: 0.4817 - val_loss: 1.0192 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 9s 728ms/step - loss: 1.0340 - acc: 0.4817 - val_loss: 1.0212 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 9s 737ms/step - loss: 1.0348 - acc: 0.4817 - val_loss: 1.0209 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 9s 763ms/step - loss: 1.0327 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 9s 742ms/step - loss: 1.0344 - acc: 0.4817 - val_loss: 1.0199 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 9s 752ms/step - loss: 1.0335 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 9s 758ms/step - loss: 1.0345 - acc: 0.4817 - val_loss: 1.0194 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 9s 762ms/step - loss: 1.0360 - acc: 0.4817 - val_loss: 1.0224 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 9s 730ms/step - loss: 1.0345 - acc: 0.4817 - val_loss: 1.0194 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 9s 768ms/step - loss: 1.0360 - acc: 0.4817 - val_loss: 1.0206 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 9s 738ms/step - loss: 1.0329 - acc: 0.4817 - val_loss: 1.0192 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 9s 740ms/step - loss: 1.0341 - acc: 0.4817 - val_loss: 1.0198 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 9s 778ms/step - loss: 1.0337 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 9s 737ms/step - loss: 1.0328 - acc: 0.4817 - val_loss: 1.0210 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 9s 748ms/step - loss: 1.0335 - acc: 0.4817 - val_loss: 1.0208 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 9s 752ms/step - loss: 1.0324 - acc: 0.4817 - val_loss: 1.0194 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 9s 770ms/step - loss: 1.0328 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 9s 775ms/step - loss: 1.0345 - acc: 0.4817 - val_loss: 1.0201 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 10s 796ms/step - loss: 1.0348 - acc: 0.4817 - val_loss: 1.0219 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 9s 758ms/step - loss: 1.0339 - acc: 0.4817 - val_loss: 1.0197 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 9s 735ms/step - loss: 1.0346 - acc: 0.4817 - val_loss: 1.0191 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 9s 726ms/step - loss: 1.0327 - acc: 0.4817 - val_loss: 1.0202 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 9s 749ms/step - loss: 1.0336 - acc: 0.4817 - val_loss: 1.0210 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 9s 747ms/step - loss: 1.0336 - acc: 0.4817 - val_loss: 1.0201 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 9s 767ms/step - loss: 1.0328 - acc: 0.4817 - val_loss: 1.0200 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 9s 732ms/step - loss: 1.0332 - acc: 0.4817 - val_loss: 1.0196 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 9s 760ms/step - loss: 1.0330 - acc: 0.4817 - val_loss: 1.0195 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 9s 748ms/step - loss: 1.0325 - acc: 0.4817 - val_loss: 1.0199 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 9s 746ms/step - loss: 1.0328 - acc: 0.4817 - val_loss: 1.0206 - val_acc: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81181625d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZHP9DcH1g-y"
      },
      "source": [
        "**Making Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDrIT2F71g-y"
      },
      "source": [
        "# Making predictions using our trained model\n",
        "predictions2 = model2.predict(x_test)\n",
        "predictions2 = np.argmax(predictions2, axis=1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xception"
      ],
      "metadata": {
        "id": "stV5ms7-4VUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,Add\n",
        "from tensorflow.keras.layers import SeparableConv2D,ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization,MaxPool2D\n",
        "from tensorflow.keras.layers import GlobalAvgPool2D\n",
        "from tensorflow.keras import Model\n",
        "# creating the Conv-Batch Norm block\n",
        "\n",
        "def conv_bn(x, filters, kernel_size, strides=1):\n",
        "    \n",
        "    x = Conv2D(filters=filters, \n",
        "               kernel_size = kernel_size, \n",
        "               strides=strides, \n",
        "               padding = 'same', \n",
        "               use_bias = False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "# creating separableConv-Batch Norm block\n",
        "\n",
        "def sep_bn(x, filters, kernel_size, strides=1):\n",
        "    \n",
        "    x = SeparableConv2D(filters=filters, \n",
        "                        kernel_size = kernel_size, \n",
        "                        strides=strides, \n",
        "                        padding = 'same', \n",
        "                        use_bias = False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "# entry flow\n",
        "\n",
        "def entry_flow(x):\n",
        "    \n",
        "    x = conv_bn(x, filters =32, kernel_size =3, strides=2)\n",
        "    x = ReLU()(x)\n",
        "    x = conv_bn(x, filters =64, kernel_size =3, strides=1)\n",
        "    tensor = ReLU()(x)\n",
        "    \n",
        "    x = sep_bn(tensor, filters = 128, kernel_size =3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 128, kernel_size =3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=128, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =256, kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =256, kernel_size=3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=256, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =728, kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =728, kernel_size=3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=728, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    return x\n",
        "# middle flow\n",
        "\n",
        "def middle_flow(tensor):\n",
        "    \n",
        "    for _ in range(8):\n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "        \n",
        "    return tensor\n",
        "# exit flow\n",
        "\n",
        "def exit_flow(tensor):\n",
        "    \n",
        "    x = ReLU()(tensor)\n",
        "    x = sep_bn(x, filters = 728,  kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 1024,  kernel_size=3)\n",
        "    x = MaxPool2D(pool_size = 3, strides = 2, padding ='same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters =1024, kernel_size=1, strides =2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = sep_bn(x, filters = 1536,  kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 2048,  kernel_size=3)\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    \n",
        "    x = Dense (units = 3, activation = 'softmax')(x)\n",
        "    \n",
        "    return x\n",
        "# model code\n",
        "\n",
        "input = Input(shape = (224,224,3))\n",
        "x = entry_flow(input)\n",
        "x = middle_flow(x)\n",
        "output = exit_flow(x)\n",
        "\n",
        "model4 = Model (inputs=input, outputs=output)\n",
        "model4.summary()"
      ],
      "metadata": {
        "id": "vyQ3M7UQ4TJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(loss='categorical_crossentropy', \n",
        "\t      optimizer='adam',\n",
        "\t      metrics=['acc'])"
      ],
      "metadata": {
        "id": "V7qPGzTH41EM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps per epoch=279/30;validation_step=120/30\n",
        "model4.fit_generator(x_train,epochs=50,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JA2PAIU461h",
        "outputId": "a9e5d7b4-922e-4821-b2f6-02d3a79d6131"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 22s 1s/step - loss: 1.9444 - acc: 0.4712 - val_loss: 1.0393 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 10s 787ms/step - loss: 0.8974 - acc: 0.6073 - val_loss: 1.0257 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 10s 793ms/step - loss: 0.7050 - acc: 0.7042 - val_loss: 1.0227 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 12s 975ms/step - loss: 0.5548 - acc: 0.7906 - val_loss: 1.0265 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 10s 797ms/step - loss: 0.4836 - acc: 0.7958 - val_loss: 1.0328 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 10s 840ms/step - loss: 0.5384 - acc: 0.7723 - val_loss: 1.0357 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 10s 817ms/step - loss: 0.4782 - acc: 0.8194 - val_loss: 1.0389 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 10s 838ms/step - loss: 0.4983 - acc: 0.8063 - val_loss: 1.0454 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 10s 807ms/step - loss: 0.4851 - acc: 0.7958 - val_loss: 1.0517 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 10s 809ms/step - loss: 0.4511 - acc: 0.7984 - val_loss: 1.0579 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 10s 860ms/step - loss: 0.3204 - acc: 0.8822 - val_loss: 1.0632 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 10s 838ms/step - loss: 0.3629 - acc: 0.8534 - val_loss: 1.0709 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 10s 802ms/step - loss: 0.2775 - acc: 0.8822 - val_loss: 1.0817 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 10s 809ms/step - loss: 0.2711 - acc: 0.8979 - val_loss: 1.0999 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 10s 819ms/step - loss: 0.3317 - acc: 0.8613 - val_loss: 1.0911 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 10s 825ms/step - loss: 0.2688 - acc: 0.8979 - val_loss: 1.0967 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 10s 827ms/step - loss: 0.2007 - acc: 0.9241 - val_loss: 1.1083 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 10s 813ms/step - loss: 0.1624 - acc: 0.9293 - val_loss: 1.1108 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 10s 808ms/step - loss: 0.2713 - acc: 0.9031 - val_loss: 1.1215 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 10s 792ms/step - loss: 0.2453 - acc: 0.8979 - val_loss: 1.1349 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 10s 842ms/step - loss: 0.1942 - acc: 0.9319 - val_loss: 1.1278 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 10s 850ms/step - loss: 0.1883 - acc: 0.9319 - val_loss: 1.1404 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 10s 831ms/step - loss: 0.2016 - acc: 0.9319 - val_loss: 1.1570 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 10s 826ms/step - loss: 0.1710 - acc: 0.9450 - val_loss: 1.1105 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 10s 804ms/step - loss: 0.1422 - acc: 0.9503 - val_loss: 1.1405 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 10s 825ms/step - loss: 0.1691 - acc: 0.9319 - val_loss: 1.1266 - val_acc: 0.4500\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 10s 818ms/step - loss: 0.1029 - acc: 0.9607 - val_loss: 1.1293 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 10s 804ms/step - loss: 0.1283 - acc: 0.9581 - val_loss: 1.0982 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 10s 803ms/step - loss: 0.0567 - acc: 0.9817 - val_loss: 1.0904 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 10s 839ms/step - loss: 0.1439 - acc: 0.9503 - val_loss: 1.0923 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 10s 826ms/step - loss: 0.1630 - acc: 0.9424 - val_loss: 0.9978 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 10s 825ms/step - loss: 0.0881 - acc: 0.9764 - val_loss: 1.0156 - val_acc: 0.4929\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 10s 820ms/step - loss: 0.1258 - acc: 0.9476 - val_loss: 1.1431 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 10s 815ms/step - loss: 0.0591 - acc: 0.9791 - val_loss: 1.2171 - val_acc: 0.5071\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 10s 829ms/step - loss: 0.1577 - acc: 0.9555 - val_loss: 1.3093 - val_acc: 0.5143\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 10s 790ms/step - loss: 0.2320 - acc: 0.9215 - val_loss: 0.9688 - val_acc: 0.5357\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 10s 814ms/step - loss: 0.1359 - acc: 0.9424 - val_loss: 0.9215 - val_acc: 0.5929\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 10s 822ms/step - loss: 0.0801 - acc: 0.9712 - val_loss: 0.7786 - val_acc: 0.6571\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 10s 843ms/step - loss: 0.0726 - acc: 0.9764 - val_loss: 0.8698 - val_acc: 0.6000\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 10s 854ms/step - loss: 0.0791 - acc: 0.9660 - val_loss: 1.1910 - val_acc: 0.4786\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 10s 816ms/step - loss: 0.1365 - acc: 0.9555 - val_loss: 0.9720 - val_acc: 0.6071\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 10s 819ms/step - loss: 0.0950 - acc: 0.9686 - val_loss: 1.8821 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 10s 798ms/step - loss: 0.0557 - acc: 0.9869 - val_loss: 2.0441 - val_acc: 0.5214\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 10s 813ms/step - loss: 0.0574 - acc: 0.9738 - val_loss: 1.6899 - val_acc: 0.6143\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 10s 845ms/step - loss: 0.0691 - acc: 0.9791 - val_loss: 1.5034 - val_acc: 0.6143\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 10s 835ms/step - loss: 0.0792 - acc: 0.9738 - val_loss: 1.2473 - val_acc: 0.6000\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 10s 842ms/step - loss: 0.0683 - acc: 0.9791 - val_loss: 2.7175 - val_acc: 0.4429\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 10s 823ms/step - loss: 0.1084 - acc: 0.9581 - val_loss: 1.9460 - val_acc: 0.4786\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 10s 807ms/step - loss: 0.0973 - acc: 0.9634 - val_loss: 2.0606 - val_acc: 0.6429\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 10s 817ms/step - loss: 0.0409 - acc: 0.9843 - val_loss: 1.8403 - val_acc: 0.6714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8090435550>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet50"
      ],
      "metadata": {
        "id": "SMKOgcxw8umg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as K\n",
        "import tensorflow as tf\n",
        "input_t = K.Input(shape=(224, 224, 3))\n",
        "res_model5 = K.applications.ResNet50(include_top=False,\n",
        "                                    weights=\"imagenet\",\n",
        "                                    input_tensor=input_t)\n",
        "\n",
        "for layer in res_model5.layers[:143]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for i, layer in enumerate(res_model5.layers):\n",
        "    print(i, layer.name, \"-\", layer.trainable)\n",
        "\n",
        "to_res = (224, 224)\n",
        "model5 = K.models.Sequential()\n",
        "model5.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res))) \n",
        "model5.add(res_model5)\n",
        "model5.add(K.layers.Flatten())\n",
        "model5.add(K.layers.BatchNormalization())\n",
        "model5.add(K.layers.Dense(256, activation='relu'))\n",
        "model5.add(K.layers.Dropout(0.5))\n",
        "model5.add(K.layers.BatchNormalization())\n",
        "model5.add(K.layers.Dense(128, activation='relu'))\n",
        "model5.add(K.layers.Dropout(0.5))\n",
        "model5.add(K.layers.BatchNormalization())\n",
        "model5.add(K.layers.Dense(64, activation='relu'))\n",
        "model5.add(K.layers.Dropout(0.5))\n",
        "model5.add(K.layers.BatchNormalization())\n",
        "model5.add(K.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "              optimizer=K.optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mRHtJmWY7VHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps per epoch=279/30;validation_step=120/30\n",
        "model5.fit_generator(x_train,epochs=100,validation_data=x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ve5FdCd8h1L",
        "outputId": "016b247b-2330-4bba-e1f7-a457791d9cc3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 17s 804ms/step - loss: 1.5753 - accuracy: 0.3298 - val_loss: 1.1215 - val_accuracy: 0.4714\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 8s 633ms/step - loss: 1.5576 - accuracy: 0.3403 - val_loss: 1.1459 - val_accuracy: 0.3643\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 8s 669ms/step - loss: 1.5145 - accuracy: 0.3508 - val_loss: 1.1469 - val_accuracy: 0.4571\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 1.4448 - accuracy: 0.4084 - val_loss: 1.1234 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 8s 642ms/step - loss: 1.4955 - accuracy: 0.3927 - val_loss: 1.1418 - val_accuracy: 0.4929\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 8s 676ms/step - loss: 1.4559 - accuracy: 0.3927 - val_loss: 1.1188 - val_accuracy: 0.5286\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 1.4069 - accuracy: 0.4031 - val_loss: 1.1316 - val_accuracy: 0.5214\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 7s 628ms/step - loss: 1.3632 - accuracy: 0.4346 - val_loss: 1.1365 - val_accuracy: 0.4929\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 7s 620ms/step - loss: 1.4144 - accuracy: 0.4110 - val_loss: 1.1540 - val_accuracy: 0.4786\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 8s 671ms/step - loss: 1.3183 - accuracy: 0.4162 - val_loss: 1.1114 - val_accuracy: 0.4357\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 8s 631ms/step - loss: 1.3903 - accuracy: 0.4110 - val_loss: 1.0832 - val_accuracy: 0.4214\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 8s 636ms/step - loss: 1.5082 - accuracy: 0.3613 - val_loss: 1.0943 - val_accuracy: 0.4071\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 8s 613ms/step - loss: 1.2616 - accuracy: 0.4607 - val_loss: 1.1028 - val_accuracy: 0.3643\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 7s 627ms/step - loss: 1.2890 - accuracy: 0.4372 - val_loss: 1.0685 - val_accuracy: 0.4214\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 7s 619ms/step - loss: 1.3296 - accuracy: 0.4319 - val_loss: 1.0890 - val_accuracy: 0.3786\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 8s 631ms/step - loss: 1.2598 - accuracy: 0.4346 - val_loss: 1.0767 - val_accuracy: 0.4143\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 8s 646ms/step - loss: 1.2696 - accuracy: 0.4503 - val_loss: 1.0453 - val_accuracy: 0.4429\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 8s 658ms/step - loss: 1.2128 - accuracy: 0.4948 - val_loss: 1.0392 - val_accuracy: 0.4143\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 8s 625ms/step - loss: 1.2906 - accuracy: 0.4424 - val_loss: 1.0340 - val_accuracy: 0.4500\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 8s 657ms/step - loss: 1.2389 - accuracy: 0.4450 - val_loss: 1.0801 - val_accuracy: 0.4357\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 1.2754 - accuracy: 0.4581 - val_loss: 1.0918 - val_accuracy: 0.4286\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 8s 647ms/step - loss: 1.2568 - accuracy: 0.4529 - val_loss: 1.0927 - val_accuracy: 0.4357\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 8s 630ms/step - loss: 1.3107 - accuracy: 0.4738 - val_loss: 1.0253 - val_accuracy: 0.4500\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 8s 636ms/step - loss: 1.2306 - accuracy: 0.4634 - val_loss: 1.0359 - val_accuracy: 0.4857\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 8s 655ms/step - loss: 1.1895 - accuracy: 0.4843 - val_loss: 1.0492 - val_accuracy: 0.4571\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 8s 652ms/step - loss: 1.2722 - accuracy: 0.4529 - val_loss: 1.0704 - val_accuracy: 0.4000\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 8s 632ms/step - loss: 1.2288 - accuracy: 0.4293 - val_loss: 1.0008 - val_accuracy: 0.5143\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 8s 654ms/step - loss: 1.2334 - accuracy: 0.5105 - val_loss: 0.9628 - val_accuracy: 0.4786\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 8s 650ms/step - loss: 1.1155 - accuracy: 0.5340 - val_loss: 0.9946 - val_accuracy: 0.4857\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 8s 652ms/step - loss: 1.2227 - accuracy: 0.4921 - val_loss: 1.0132 - val_accuracy: 0.4571\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 8s 632ms/step - loss: 1.1777 - accuracy: 0.4607 - val_loss: 1.0079 - val_accuracy: 0.4714\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 8s 661ms/step - loss: 1.1958 - accuracy: 0.4529 - val_loss: 0.9873 - val_accuracy: 0.4929\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 8s 637ms/step - loss: 1.2716 - accuracy: 0.4660 - val_loss: 1.0157 - val_accuracy: 0.4929\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 8s 649ms/step - loss: 1.3123 - accuracy: 0.4372 - val_loss: 1.0533 - val_accuracy: 0.4714\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 8s 671ms/step - loss: 1.1877 - accuracy: 0.4817 - val_loss: 1.1845 - val_accuracy: 0.4571\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 8s 651ms/step - loss: 1.1984 - accuracy: 0.4712 - val_loss: 1.2470 - val_accuracy: 0.4214\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 8s 629ms/step - loss: 1.1592 - accuracy: 0.5052 - val_loss: 1.3357 - val_accuracy: 0.3786\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 8s 648ms/step - loss: 1.1963 - accuracy: 0.4607 - val_loss: 1.2009 - val_accuracy: 0.4357\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 8s 643ms/step - loss: 1.1929 - accuracy: 0.4529 - val_loss: 1.1492 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 8s 649ms/step - loss: 1.1262 - accuracy: 0.4791 - val_loss: 1.1383 - val_accuracy: 0.4857\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 8s 637ms/step - loss: 1.1501 - accuracy: 0.5026 - val_loss: 1.2010 - val_accuracy: 0.4786\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 8s 667ms/step - loss: 1.1682 - accuracy: 0.4791 - val_loss: 1.1707 - val_accuracy: 0.4857\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 8s 654ms/step - loss: 1.1340 - accuracy: 0.4974 - val_loss: 1.1199 - val_accuracy: 0.4929\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 8s 649ms/step - loss: 1.2028 - accuracy: 0.5288 - val_loss: 1.2191 - val_accuracy: 0.4429\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 8s 649ms/step - loss: 1.1799 - accuracy: 0.5052 - val_loss: 1.1091 - val_accuracy: 0.4643\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 8s 650ms/step - loss: 1.1607 - accuracy: 0.4895 - val_loss: 1.0843 - val_accuracy: 0.5214\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 1.2009 - accuracy: 0.4791 - val_loss: 1.0489 - val_accuracy: 0.5214\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 8s 639ms/step - loss: 1.1304 - accuracy: 0.4948 - val_loss: 1.0534 - val_accuracy: 0.5286\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 8s 662ms/step - loss: 1.1504 - accuracy: 0.5052 - val_loss: 1.0073 - val_accuracy: 0.5429\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 8s 644ms/step - loss: 1.2099 - accuracy: 0.5105 - val_loss: 1.0834 - val_accuracy: 0.5214\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 8s 644ms/step - loss: 1.1705 - accuracy: 0.5131 - val_loss: 1.0200 - val_accuracy: 0.5571\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 1.0559 - accuracy: 0.5576 - val_loss: 1.1192 - val_accuracy: 0.5143\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 8s 642ms/step - loss: 1.0981 - accuracy: 0.4921 - val_loss: 1.1733 - val_accuracy: 0.4929\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 8s 652ms/step - loss: 1.1161 - accuracy: 0.5052 - val_loss: 1.1549 - val_accuracy: 0.4714\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 8s 651ms/step - loss: 1.0504 - accuracy: 0.5393 - val_loss: 1.1303 - val_accuracy: 0.5071\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 8s 670ms/step - loss: 1.1535 - accuracy: 0.5262 - val_loss: 1.2150 - val_accuracy: 0.4786\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 8s 630ms/step - loss: 1.0363 - accuracy: 0.5733 - val_loss: 1.1962 - val_accuracy: 0.4857\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 8s 644ms/step - loss: 1.1541 - accuracy: 0.5052 - val_loss: 1.1607 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 8s 636ms/step - loss: 1.0073 - accuracy: 0.5733 - val_loss: 1.1996 - val_accuracy: 0.4857\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 8s 627ms/step - loss: 1.0357 - accuracy: 0.5340 - val_loss: 1.2108 - val_accuracy: 0.4571\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 8s 633ms/step - loss: 1.0806 - accuracy: 0.5183 - val_loss: 1.1978 - val_accuracy: 0.4714\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 8s 646ms/step - loss: 1.0270 - accuracy: 0.5524 - val_loss: 1.1129 - val_accuracy: 0.4786\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 8s 659ms/step - loss: 1.0808 - accuracy: 0.5157 - val_loss: 1.1648 - val_accuracy: 0.4786\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 8s 647ms/step - loss: 1.1540 - accuracy: 0.5026 - val_loss: 1.1890 - val_accuracy: 0.4714\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 8s 676ms/step - loss: 1.1530 - accuracy: 0.5000 - val_loss: 1.0919 - val_accuracy: 0.4714\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 8s 661ms/step - loss: 1.1722 - accuracy: 0.4869 - val_loss: 1.1871 - val_accuracy: 0.4500\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 8s 644ms/step - loss: 1.1084 - accuracy: 0.5393 - val_loss: 1.0746 - val_accuracy: 0.5214\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 8s 636ms/step - loss: 1.1070 - accuracy: 0.5288 - val_loss: 1.0615 - val_accuracy: 0.5500\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 8s 630ms/step - loss: 1.1100 - accuracy: 0.5209 - val_loss: 1.0157 - val_accuracy: 0.5786\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 8s 641ms/step - loss: 0.9915 - accuracy: 0.5550 - val_loss: 1.0270 - val_accuracy: 0.5714\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 8s 631ms/step - loss: 1.0155 - accuracy: 0.5864 - val_loss: 1.0161 - val_accuracy: 0.5429\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 8s 637ms/step - loss: 1.0577 - accuracy: 0.4921 - val_loss: 1.0614 - val_accuracy: 0.5929\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 8s 646ms/step - loss: 1.1568 - accuracy: 0.5314 - val_loss: 1.1494 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 8s 666ms/step - loss: 1.0488 - accuracy: 0.5262 - val_loss: 1.0917 - val_accuracy: 0.5143\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 8s 659ms/step - loss: 1.0901 - accuracy: 0.5340 - val_loss: 1.0457 - val_accuracy: 0.4786\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.9416 - accuracy: 0.5942 - val_loss: 1.0410 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 8s 623ms/step - loss: 0.9481 - accuracy: 0.5864 - val_loss: 0.9943 - val_accuracy: 0.5143\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 8s 633ms/step - loss: 0.9994 - accuracy: 0.5576 - val_loss: 0.9801 - val_accuracy: 0.5786\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 8s 630ms/step - loss: 1.0447 - accuracy: 0.5314 - val_loss: 1.0581 - val_accuracy: 0.5643\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 8s 664ms/step - loss: 0.9400 - accuracy: 0.5654 - val_loss: 1.0463 - val_accuracy: 0.5714\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 8s 659ms/step - loss: 0.9846 - accuracy: 0.5733 - val_loss: 0.9704 - val_accuracy: 0.5929\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 0.9788 - accuracy: 0.5890 - val_loss: 0.9808 - val_accuracy: 0.5857\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 1.0296 - accuracy: 0.5838 - val_loss: 1.0155 - val_accuracy: 0.6143\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 8s 615ms/step - loss: 0.9180 - accuracy: 0.6099 - val_loss: 0.9842 - val_accuracy: 0.5786\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 8s 651ms/step - loss: 0.9724 - accuracy: 0.5942 - val_loss: 0.9796 - val_accuracy: 0.6071\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 8s 637ms/step - loss: 0.9508 - accuracy: 0.6230 - val_loss: 0.9433 - val_accuracy: 0.6071\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 8s 642ms/step - loss: 0.9463 - accuracy: 0.5995 - val_loss: 0.9516 - val_accuracy: 0.5929\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 8s 650ms/step - loss: 1.0159 - accuracy: 0.5314 - val_loss: 1.0359 - val_accuracy: 0.6143\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 7s 626ms/step - loss: 1.0985 - accuracy: 0.5550 - val_loss: 0.9831 - val_accuracy: 0.6000\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 8s 629ms/step - loss: 0.9742 - accuracy: 0.5916 - val_loss: 0.9861 - val_accuracy: 0.5714\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 7s 626ms/step - loss: 1.0325 - accuracy: 0.5445 - val_loss: 1.0269 - val_accuracy: 0.5929\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 8s 651ms/step - loss: 0.9441 - accuracy: 0.5628 - val_loss: 1.0297 - val_accuracy: 0.6429\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 8s 641ms/step - loss: 0.9315 - accuracy: 0.5759 - val_loss: 0.9850 - val_accuracy: 0.6571\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 8s 660ms/step - loss: 0.9178 - accuracy: 0.6204 - val_loss: 1.0178 - val_accuracy: 0.6214\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 8s 666ms/step - loss: 0.9532 - accuracy: 0.5916 - val_loss: 1.0361 - val_accuracy: 0.5714\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 8s 633ms/step - loss: 0.8829 - accuracy: 0.6440 - val_loss: 1.0273 - val_accuracy: 0.5571\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 8s 642ms/step - loss: 0.8803 - accuracy: 0.6257 - val_loss: 1.0849 - val_accuracy: 0.5571\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 7s 623ms/step - loss: 0.8697 - accuracy: 0.6283 - val_loss: 1.0831 - val_accuracy: 0.5643\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 8s 643ms/step - loss: 0.9746 - accuracy: 0.6021 - val_loss: 1.2538 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 8s 639ms/step - loss: 0.8883 - accuracy: 0.5969 - val_loss: 1.3156 - val_accuracy: 0.4571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8090b8c510>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}